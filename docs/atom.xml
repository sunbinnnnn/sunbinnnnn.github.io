<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Neil&#39;s blog</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2022-05-12T08:28:23.618Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>NeilSun</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Go并发</title>
    <link href="http://example.com/2022/05/12/Go%E5%B9%B6%E5%8F%91/"/>
    <id>http://example.com/2022/05/12/Go%E5%B9%B6%E5%8F%91/</id>
    <published>2022-05-12T07:11:36.000Z</published>
    <updated>2022-05-12T08:28:23.618Z</updated>
    
    <content type="html"><![CDATA[<p>并发问题是在大型项目开发过程中不可绕过的问题，而Go以其对并发的性能优异而得名，那Golang对并发场景的优势以及对并发问题的解决原理是如何的呢？</p><span id="more"></span><h2 id="并发原语"><a href="#并发原语" class="headerlink" title="并发原语"></a>并发原语</h2><p>原语一般是指内核提供给核外调用的过程或者函数成为原语（primitive），原语在执行过程中不允许中断。而并发原语一般是指原语的并发实现</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;并发问题是在大型项目开发过程中不可绕过的问题，而Go以其对并发的性能优异而得名，那Golang对并发场景的优势以及对并发问题的解决原理是如何的呢？&lt;/p&gt;</summary>
    
    
    
    
    <category term="Golang 并发问题" scheme="http://example.com/tags/Golang-%E5%B9%B6%E5%8F%91%E9%97%AE%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>openstack-helm离线部署</title>
    <link href="http://example.com/2022/04/19/openstack-helm%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2/"/>
    <id>http://example.com/2022/04/19/openstack-helm%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2/</id>
    <published>2022-04-19T06:27:23.000Z</published>
    <updated>2022-05-17T12:37:47.779Z</updated>
    
    <content type="html"><![CDATA[<table><thead><tr><th>节点名</th><th>角色</th></tr></thead><tbody><tr><td>knode1</td><td>融合节点</td></tr><tr><td>knode2</td><td>融合节点</td></tr><tr><td>knode3</td><td>融合节点</td></tr><tr><td>knode4</td><td>计算、存储节点</td></tr></tbody></table><blockquote><p>文章中引用的chart包是经过改造的，如需要，请联系笔者</p><p>Linux发行版为centos7，openstack版本为train版（train以上版本无法完全适配centos7 3.10 kernel）</p></blockquote><h1 id="一-helm准备"><a href="#一-helm准备" class="headerlink" title="一.helm准备"></a>一.helm准备</h1><p>1.将helm二进制复制到<code>/usr/bin</code>下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp binary&#x2F;helm &#x2F;usr&#x2F;bin&#x2F;helm</span><br><span class="line">chmod +x &#x2F;usr&#x2F;bin&#x2F;helm</span><br></pre></td></tr></table></figure><p>2.去除master节点的污点</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl taint nodes knode1 node-role.kubernetes.io&#x2F;master:NoSchedule-</span><br><span class="line">kubectl taint nodes knode2 node-role.kubernetes.io&#x2F;master:NoSchedule-</span><br><span class="line">kubectl taint nodes knode3 node-role.kubernetes.io&#x2F;master:NoSchedule-</span><br></pre></td></tr></table></figure><p>3.为节点添加label（3控制同时作为控制节点和计算节点，单独的node4作为单独计算节点，所有节点默认都是存储节点，控制节点作为进出口流量节点）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl label nodes knode1 ceph-control-plane&#x3D;enabled openstack-control-plane&#x3D;enabled  openvswitch&#x3D;enabled openstack-compute-node&#x3D;enabled ingress-node&#x3D;enabled</span><br><span class="line">kubectl label nodes knode2 ceph-control-plane&#x3D;enabled openstack-control-plane&#x3D;enabled  openvswitch&#x3D;enabled openstack-compute-node&#x3D;enabled ingress-node&#x3D;enabled</span><br><span class="line">kubectl label nodes knode3 ceph-control-plane&#x3D;enabled openstack-control-plane&#x3D;enabled  openvswitch&#x3D;enabled openstack-compute-node&#x3D;enabled ingress-node&#x3D;enabled</span><br><span class="line">kubectl label nodes knode4 openstack-compute-node&#x3D;enabled openvswitch&#x3D;enabled </span><br></pre></td></tr></table></figure><h1 id="二-安装rook-ceph"><a href="#二-安装rook-ceph" class="headerlink" title="二.安装rook-ceph"></a>二.安装rook-ceph</h1><p>1.安装rook-ceph-operator</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">helm install --create-namespace --namespace rook-ceph rook-ceph .&#x2F;charts&#x2F;rook-ceph-0.0.1.tgz  --set image.tag&#x3D;v1.8.8</span><br><span class="line"># wait for operator start</span><br><span class="line">sleep 10</span><br></pre></td></tr></table></figure><p>2.创建ceph cluster、storageClass</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm install --create-namespace --namespace rook-ceph rook-ceph-cluster .&#x2F;charts&#x2F;rook-ceph-cluster-0.0.1.tgz --set cephClusterSpec.dashboard.enabled&#x3D;false</span><br></pre></td></tr></table></figure><blockquote><p>删除时，需要先执行<code>kubectl -n rook-ceph patch cephcluster rook-ceph --type merge -p &#39;&#123;&quot;spec&quot;:&#123;&quot;cleanupPolicy&quot;:&#123;&quot;confirmation&quot;:&quot;yes-really-destroy-data&quot;&#125;&#125;&#125;&#39;</code></p></blockquote><p>3.等待集群创建完成</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">kubectl  wait --for&#x3D;condition&#x3D;Ready -n rook-ceph cephcluster rook-ceph --timeout&#x3D;1800s</span><br><span class="line"> </span><br><span class="line"># 等待osd pod正常创建并启动</span><br><span class="line">sleep 180</span><br><span class="line"></span><br><span class="line">kubectl get pod -n rook-ceph # 确认所有pod都处于Running或Complete状态，确保4个osd成功创建（集群Ready后，OSD不一定完全启动），创建成功后才能进行下一步</span><br><span class="line"># 查看ceph集群状态,HEALTH_WARN或HEALTH_OK均可</span><br><span class="line">kubectl exec -it -n rook-ceph &#96;kubectl  get pod -n rook-ceph -owide|grep tools|awk &#39;&#123; print $1 &#125;&#39;&#96; -- ceph -s</span><br></pre></td></tr></table></figure><blockquote><p>1.ceph osd无法启动？</p><p>查看prepare osd job pod的日志，确认各节点有一块以上未使用的磁盘，operator轮询过程可能比较慢，可能需要等待5分钟以上才能创建出osd</p><p>2.新增节点osd未被添加？</p><p>rook operator会以周期频率检查新加入节点，如果长时间未被添加，手动重启rook operator pod，1分钟左右新节点会被加入</p></blockquote><h1 id="三-安装Registry、ChartMuseum"><a href="#三-安装Registry、ChartMuseum" class="headerlink" title="三.安装Registry、ChartMuseum"></a>三.安装Registry、ChartMuseum</h1><p>1.安装并配置docker-registry</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">helm install docker-registry --create-namespace --namespace registry .&#x2F;charts&#x2F;docker-registry-2.1.0.tgz --set persistence.size&#x3D;60Gi</span><br><span class="line">kubectl get pod  -n registry |grep 1&#x2F;1 # 确认registry pod成功创建，成功后才能进行下一步</span><br></pre></td></tr></table></figure><p>2.设置私有仓库和设置dns地址（<strong>需要在所有节点执行</strong>）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># replace nameserver to kubedns, every nodes should do below</span><br><span class="line">cat &lt;&lt;EOF | sudo tee &#x2F;etc&#x2F;docker&#x2F;daemon.json</span><br><span class="line">&#123;</span><br><span class="line">  &quot;exec-opts&quot;: [&quot;native.cgroupdriver&#x3D;systemd&quot;],</span><br><span class="line">  &quot;log-driver&quot;: &quot;json-file&quot;,</span><br><span class="line">  &quot;log-opts&quot;: &#123;</span><br><span class="line">    &quot;max-size&quot;: &quot;100m&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;storage-driver&quot;: &quot;overlay2&quot;,</span><br><span class="line">  &quot;insecure-registries&quot; : [&quot;docker-registry.registry.svc.cluster.local&quot;]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br><span class="line">sleep 30</span><br><span class="line">kubectl  wait --for&#x3D;condition&#x3D;Available -n registry deploy docker-registry --timeout&#x3D;120s</span><br></pre></td></tr></table></figure><blockquote><p>测试：</p><p>docker tag rook/ceph:v1.8.8 docker-registry.registry.svc.cluster.local/ceph:v1.8.8</p><p>docker push docker-registry.registry.svc.cluster.local/ceph:v1.8.8</p></blockquote><p>3.导入镜像到registry</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 添加kubedns，所有节点都需要配置该nameserver，否则kubelet无法拉取镜像，node节点如果无法执行kubectl命令，则需要从master节点拷贝</span><br><span class="line">NAMESERVER&#x3D;&#96;kubectl get svc -n kube-system|awk &#39;&#123; print $3 &#125;&#39;|grep -v IP&#96;</span><br><span class="line">echo &quot;nameserver $NAMESERVER&quot; &gt; &#x2F;etc&#x2F;resolv.conf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 修改Kubelet ImageGC配置，防止kubelet删除节点镜像</span><br><span class="line">echo &quot;imageGCHighThresholdPercent: 100&quot; &gt;&gt; &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;config.yaml</span><br><span class="line">systemctl restart kubelet</span><br><span class="line"></span><br><span class="line">docker load -q &lt; images&#x2F;components&#x2F;all_components_images.tar.gz</span><br><span class="line">docker images | grep docker-registry.registry.svc.cluster.local | awk &#39;&#123;print &quot;docker push -q &quot;$1&quot;:&quot;$2&#125;&#39;|sh</span><br><span class="line"></span><br><span class="line"># 复原kubelet配置</span><br><span class="line">sed -i &#39;&#x2F;imageGCHighThresholdPercent&#x2F;d&#39;  &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;config.yaml</span><br><span class="line">systemctl restart kubelet</span><br><span class="line">sleep 30</span><br></pre></td></tr></table></figure><p>4.安装并配置chartmuseum</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">helm install chartmuseum --create-namespace --namespace registry .&#x2F;charts&#x2F;chartmuseum-3.7.0.tgz</span><br><span class="line">kubectl  wait --for&#x3D;condition&#x3D;Available -n registry deploy chartmuseum --timeout&#x3D;120s</span><br><span class="line">helm repo add chartmuseum http:&#x2F;&#x2F;chartmuseum.registry.svc.cluster.local:8080&#x2F;</span><br><span class="line">helm repo update</span><br></pre></td></tr></table></figure><p>5.安装并配置openstackclient</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"># 在所有控制节点安装</span><br><span class="line">yum install -y python3</span><br><span class="line">mkdir -p &#x2F;tmp&#x2F;pip_packs&#x2F;</span><br><span class="line">tar -zxf .&#x2F;pip_packs&#x2F;openstackclient_pip_packs.tar.gz -C &#x2F;tmp&#x2F;pip_packs&#x2F;</span><br><span class="line">sudo -H -E pip3 install  --no-index --find-links&#x3D;&#x2F;tmp&#x2F;pip_packs&#x2F; cmd2 python-openstackclient python-heatclient --ignore-installed</span><br><span class="line"></span><br><span class="line">sudo -H mkdir -p &#x2F;etc&#x2F;openstack</span><br><span class="line">sudo -H chown -R $(id -un): &#x2F;etc&#x2F;openstack</span><br><span class="line">FEATURE_GATE&#x3D;&quot;tls&quot;; if [[ $&#123;FEATURE_GATES&#x2F;&#x2F;,&#x2F; &#125; &#x3D;~ (^|[[:space:]])$&#123;FEATURE_GATE&#125;($|[[:space:]]) ]]; then</span><br><span class="line">  tee &#x2F;etc&#x2F;openstack&#x2F;clouds.yaml &lt;&lt; EOF</span><br><span class="line">  clouds:</span><br><span class="line">    openstack_helm:</span><br><span class="line">      region_name: RegionOne</span><br><span class="line">      identity_api_version: 3</span><br><span class="line">      volume_api_version: 3</span><br><span class="line">      cacert: &#x2F;etc&#x2F;openstack-helm&#x2F;certs&#x2F;ca&#x2F;ca.pem</span><br><span class="line">      auth:</span><br><span class="line">        username: &#39;admin&#39;</span><br><span class="line">        password: &#39;password&#39;</span><br><span class="line">        project_name: &#39;admin&#39;</span><br><span class="line">        project_domain_name: &#39;default&#39;</span><br><span class="line">        user_domain_name: &#39;default&#39;</span><br><span class="line">        auth_url: &#39;https:&#x2F;&#x2F;keystone-api.openstack.svc.cluster.local:5000&#x2F;v3&#39;</span><br><span class="line">EOF</span><br><span class="line">else</span><br><span class="line">  tee &#x2F;etc&#x2F;openstack&#x2F;clouds.yaml &lt;&lt; EOF</span><br><span class="line">  clouds:</span><br><span class="line">    openstack_helm:</span><br><span class="line">      region_name: RegionOne</span><br><span class="line">      identity_api_version: 3</span><br><span class="line">      volume_api_version: 3</span><br><span class="line">      auth:</span><br><span class="line">        username: &#39;admin&#39;</span><br><span class="line">        password: &#39;password&#39;</span><br><span class="line">        project_name: &#39;admin&#39;</span><br><span class="line">        project_domain_name: &#39;default&#39;</span><br><span class="line">        user_domain_name: &#39;default&#39;</span><br><span class="line">        auth_url: &#39;http:&#x2F;&#x2F;keystone-api.openstack.svc.cluster.local:5000&#x2F;v3&#39;</span><br><span class="line">EOF</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p>6.导入charts</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for i in &#96;ls .&#x2F;charts&#96;;do curl --data-binary &quot;@.&#x2F;charts&#x2F;$i&quot; http:&#x2F;&#x2F;chartmuseum.registry.svc.cluster.local:8080&#x2F;api&#x2F;charts;done</span><br><span class="line">helm repo update</span><br></pre></td></tr></table></figure><h1 id="三-部署、配置平台中间件"><a href="#三-部署、配置平台中间件" class="headerlink" title="三.部署、配置平台中间件"></a>三.部署、配置平台中间件</h1><p>1.安装ingress-controller</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">helm install ingress-controller --namespace kube-system chartmuseum&#x2F;ingress-nginx</span><br><span class="line"># 等待pod启动</span><br><span class="line">[root@knode1 ~]# kubectl  get ds -n kube-system|grep ingress-controller-ingress-nginx-controller</span><br><span class="line">ingress-controller-ingress-nginx-controller   4         4         4       4            4           kubernetes.io&#x2F;os&#x3D;linux   37m</span><br></pre></td></tr></table></figure><p>2.部署mariadb</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">helm install mariadb --create-namespace --namespace openstack chartmuseum&#x2F;mariadb --set volume.enabled&#x3D;true --set volume.class_name&#x3D;ceph-block --set volume.size&#x3D;10Gi --set pod.replicas.server&#x3D;3</span><br><span class="line"></span><br><span class="line"># 等待3个pod启动</span><br><span class="line">kubectl  wait --for&#x3D;condition&#x3D;Ready -n openstack pods&#x2F;mariadb-server-2 --timeout 500s</span><br><span class="line">kubectl  wait --for&#x3D;condition&#x3D;Ready -n openstack pods&#x2F;mariadb-server-1 --timeout 500s</span><br><span class="line">kubectl  wait --for&#x3D;condition&#x3D;Ready -n openstack pods&#x2F;mariadb-server-0 --timeout 500s</span><br></pre></td></tr></table></figure><blockquote><p>Pod一直无法启动？</p><p>一般情况下是mariaDB集群时间采样与实际时间不符导致，需要检查以下两点：</p><p>1.ntp时间是否同步</p><p>2.是否之前部署过后进行了helm delete，如果是，需要手动删除openstack namespace下，mariaDB相关的configmap和pvc，删除后重新部署即可</p></blockquote><p>3.部署RabbitMQ</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">helm upgrade --install rabbitmq chartmuseum&#x2F;rabbitmq \</span><br><span class="line">    --namespace&#x3D;openstack \</span><br><span class="line">    --set volume.enabled&#x3D;true \</span><br><span class="line">    --set pod.replicas.server&#x3D;2 \</span><br><span class="line">    --set volume.class_name&#x3D;ceph-block</span><br></pre></td></tr></table></figure><p>4.部署Memcached</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">helm upgrade --install memcached chartmuseum&#x2F;memcached \</span><br><span class="line">    --namespace&#x3D;openstack</span><br><span class="line"></span><br><span class="line"># 等待pod启动</span><br><span class="line">kubectl  wait --for&#x3D;condition&#x3D;Available -n openstack deployment&#x2F;memcached-memcached --timeout&#x3D;300s</span><br></pre></td></tr></table></figure><h1 id="四-部署openstack相关组件"><a href="#四-部署openstack相关组件" class="headerlink" title="四.部署openstack相关组件"></a>四.部署openstack相关组件</h1><p>1.部署keystone</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">helm upgrade --install keystone chartmuseum&#x2F;keystone     --namespace&#x3D;openstack     --set pod.replicas.api&#x3D;2 --timeout 1800s</span><br><span class="line"></span><br><span class="line">kubectl  wait --for&#x3D;condition&#x3D;Available -n openstack deploy&#x2F;keystone-api --timeout&#x3D;300s</span><br><span class="line"># 验证</span><br><span class="line">export OS_CLOUD&#x3D;openstack_helm</span><br><span class="line">openstack endpoint list</span><br></pre></td></tr></table></figure><p>2.部署glance</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">helm upgrade --install glance chartmuseum&#x2F;glance \</span><br><span class="line">  --namespace&#x3D;openstack --timeout 1800s</span><br><span class="line">  </span><br><span class="line"># 查看pod状态</span><br><span class="line">kubectl  get pod -n openstack|grep glance|grep -v Completed</span><br><span class="line"># 验证</span><br><span class="line">export OS_CLOUD&#x3D;openstack_helm</span><br><span class="line">openstack image create &quot;Cirros 0.3.5 64-bit&quot; --min-disk 1 --disk-format qcow2 --file .&#x2F;images&#x2F;cirros-0.3.5-x86_64-disk.img --container-format bare  --public</span><br><span class="line">openstack image list</span><br></pre></td></tr></table></figure><p>3.部署cinder</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">CEPHKEY&#x3D;&#96;kubectl get secret -n rook-ceph rook-ceph-admin-keyring -ojsonpath&#x3D;&#39;&#123;.data.keyring&#125;&#39;|base64 -d|grep key|awk &#39;&#123; print $3 &#125;&#39;&#96;</span><br><span class="line">MON_LIST&#x3D;($(kubectl  get svc -n rook-ceph|grep mon|awk &#39;&#123; print $1 &#125;&#39;))</span><br><span class="line">cat &lt;&lt; EOF | sudo tee &#x2F;tmp&#x2F;cinder_ceph.yaml</span><br><span class="line">---</span><br><span class="line">conf:</span><br><span class="line">  ceph:</span><br><span class="line">    admin_keyring: $CEPHKEY</span><br><span class="line">  cinder:</span><br><span class="line">    DEFAULT:</span><br><span class="line">      enabled_backends: &quot;rook-ceph&quot;</span><br><span class="line">      backup_ceph_user: &quot;admin&quot;</span><br><span class="line">  backends:</span><br><span class="line">    rook-ceph:</span><br><span class="line">      volume_driver: cinder.volume.drivers.rbd.RBDDriver</span><br><span class="line">      volume_backend_name: rook-ceph</span><br><span class="line">      rbd_pool: cinder.volumes</span><br><span class="line">      rbd_flatten_volume_from_snapshot: False</span><br><span class="line">      report_discard_supported: True</span><br><span class="line">      rbd_max_clone_depth: 5</span><br><span class="line">      rbd_store_chunk_size: 4</span><br><span class="line">      rados_connect_timeout: -1</span><br><span class="line">      rbd_user: admin</span><br><span class="line">      rbd_secret_uuid: 3f0133e4-8384-4743-9473-fecacc095c74</span><br><span class="line">      image_volume_cache_enabled: True</span><br><span class="line">      image_volume_cache_max_size_gb: 200</span><br><span class="line">      image_volume_cache_max_count: 50</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF | sudo tee &#x2F;tmp&#x2F;ceph-ceph.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: ceph-etc</span><br><span class="line">  namespace: openstack</span><br><span class="line">data:</span><br><span class="line">  ceph.conf: |</span><br><span class="line">    [global]</span><br><span class="line">    mon_host &#x3D; $&#123;MON_LIST[0]&#125;.rook-ceph.svc.cluster.local:6789,$&#123;MON_LIST[1]&#125;.rook-ceph.svc.cluster.local:6789,$&#123;MON_LIST[2]&#125;.rook-ceph.svc.cluster.local:6789</span><br><span class="line"></span><br><span class="line">    [client.admin]</span><br><span class="line">    keyring &#x3D; &#x2F;etc&#x2F;ceph&#x2F;ceph.client.admin.keyring</span><br><span class="line">    caps mds &#x3D; &quot;allow *&quot;</span><br><span class="line">    caps mon &#x3D; &quot;allow *&quot;</span><br><span class="line">    caps osd &#x3D; &quot;allow *&quot;</span><br><span class="line">    caps mgr &#x3D; &quot;allow *&quot;</span><br><span class="line"></span><br><span class="line">EOF</span><br><span class="line">kubectl apply -f &#x2F;tmp&#x2F;ceph-ceph.yaml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">helm upgrade --install cinder chartmuseum&#x2F;cinder \</span><br><span class="line">  --namespace&#x3D;openstack \</span><br><span class="line">  --values&#x3D;&#x2F;tmp&#x2F;cinder_ceph.yaml --timeout 1800s</span><br><span class="line">kubectl  wait --for&#x3D;condition&#x3D;Available -n openstack deploy&#x2F;cinder-api --timeout&#x3D;300s</span><br><span class="line"># 验证</span><br><span class="line">export OS_CLOUD&#x3D;openstack_helm</span><br><span class="line">openstack volume type list</span><br><span class="line">openstack volume type list --default</span><br></pre></td></tr></table></figure><p>4.部署openvswitch</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">helm upgrade --install openvswitch chartmuseum&#x2F;openvswitch \</span><br><span class="line">  --namespace&#x3D;openstack</span><br><span class="line">sleep 180</span><br><span class="line"># 验证, 查看daemonSet正常启动</span><br><span class="line">[root@master1 ~]# kubectl  get ds -n openstack</span><br><span class="line">NAME                   DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR         AGE</span><br><span class="line">openvswitch-db         4         4         4       4            4           openvswitch&#x3D;enabled   2m19s</span><br><span class="line">openvswitch-vswitchd   4         4         4       4            4           openvswitch&#x3D;enabled   2m19s</span><br></pre></td></tr></table></figure><p>5.部署Libvirt</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">CEPHKEY&#x3D;&#96;kubectl get secret -n rook-ceph rook-ceph-admin-keyring -ojsonpath&#x3D;&#39;&#123;.data.keyring&#125;&#39;|base64 -d|grep key|awk &#39;&#123; print $3 &#125;&#39;&#96;</span><br><span class="line">cat &lt;&lt; EOF | sudo tee &#x2F;tmp&#x2F;libvirt_ceph.yaml</span><br><span class="line">---</span><br><span class="line">conf:</span><br><span class="line">  ceph:</span><br><span class="line">    enabled: true</span><br><span class="line">    admin_keyring: $CEPHKEY</span><br><span class="line">    cinder:</span><br><span class="line">      user: &quot;admin&quot;</span><br><span class="line">      keyring: $CEPHKEY</span><br><span class="line">      secret_uuid: 3f0133e4-8384-4743-9473-fecacc095c74</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">EOF</span><br><span class="line">helm upgrade --install libvirt chartmuseum&#x2F;libvirt \</span><br><span class="line">  --namespace&#x3D;openstack --values&#x3D;&#x2F;tmp&#x2F;libvirt_ceph.yaml --timeout 1800s</span><br></pre></td></tr></table></figure><blockquote><p>在没有安装neutron的情况下，libvirt是无法完全启动的，pod处于init状态，查看init日志，kubectl logs -n openstack libvirt-libvirt-default-7trpd -c init，可以看到Entrypoint WARNING: 2022/05/10 02:55:23 entrypoint.go:72: Resolving dependency Pod on same host with labels map[application:neutron component:neutron-ovs-agent] in namespace openstack failed: Found no pods matching labels: map[application:neutron component:neutron-ovs-agent]</p><p>稍后在neutron部署完成后，在验证libvirt是否正常启动</p></blockquote><p>6.部署nova、neutron（Compute Kit）</p><p><strong>需要注意neutron外部网卡的配置！！</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># 计算组件（Compute Kit）安装过程会比较久（大约20~40分钟），可以通过循环检测判定安装状态</span><br><span class="line">CEPHKEY&#x3D;&#96;kubectl get secret -n rook-ceph rook-ceph-admin-keyring -ojsonpath&#x3D;&#39;&#123;.data.keyring&#125;&#39;|base64 -d|grep key|awk &#39;&#123; print $3 &#125;&#39;&#96;</span><br><span class="line"></span><br><span class="line"># VNCPROXY用到的VIP需要根据实际环境情况传入，脚本只在keepalive按照固定配置情况下生效！！</span><br><span class="line">APISERVER_VIP&#x3D;&#96;cat &#x2F;etc&#x2F;keepalived&#x2F;keepalived.conf |grep -A 1 virtual_ipaddress|grep -v virtual_ipaddress|awk &#39;&#123;print $1&#125;&#39;&#96;</span><br><span class="line"></span><br><span class="line">cat &lt;&lt; EOF | sudo tee &#x2F;tmp&#x2F;nova_ceph.yaml</span><br><span class="line">---</span><br><span class="line">pod:</span><br><span class="line">  replicas:</span><br><span class="line">    osapi: 2</span><br><span class="line">    conductor: 2</span><br><span class="line">    novncproxy: 3</span><br><span class="line">conf:</span><br><span class="line">  ceph:</span><br><span class="line">    enabled: true</span><br><span class="line">    admin_keyring: $CEPHKEY</span><br><span class="line">    cinder:</span><br><span class="line">      user: &quot;admin&quot;</span><br><span class="line">      keyring: $CEPHKEY</span><br><span class="line">      secret_uuid: 3f0133e4-8384-4743-9473-fecacc095c74</span><br><span class="line">  nova:</span><br><span class="line">    libvirt:</span><br><span class="line">      rbd_secret_uuid: 3f0133e4-8384-4743-9473-fecacc095c74</span><br><span class="line">      rbd_user: admin</span><br><span class="line">...</span><br><span class="line">EOF</span><br><span class="line">#NOTE: Deploy nova</span><br><span class="line">if [ &quot;x$(systemd-detect-virt)&quot; &#x3D;&#x3D; &quot;xnone&quot; ]; then</span><br><span class="line">  echo &#39;OSH is not being deployed in virtualized environment&#39;</span><br><span class="line">  helm upgrade --install nova chartmuseum&#x2F;nova \</span><br><span class="line">      --namespace&#x3D;openstack \</span><br><span class="line">      --values&#x3D;&#x2F;tmp&#x2F;nova_ceph.yaml \</span><br><span class="line">      --set bootstrap.wait_for_computes.enabled&#x3D;true \</span><br><span class="line">      --set conf.nova.vnc.novncproxy_base_url&#x3D;&quot;http:&#x2F;&#x2F;$&#123;APISERVER_VIP&#125;&#x2F;vnc_auto.html&quot;</span><br><span class="line">      --timeout 1800s</span><br><span class="line">else</span><br><span class="line">  echo &#39;OSH is being deployed in virtualized environment, using qemu for nova&#39;</span><br><span class="line">  helm upgrade --install nova chartmuseum&#x2F;nova \</span><br><span class="line">      --namespace&#x3D;openstack \</span><br><span class="line">      --values&#x3D;&#x2F;tmp&#x2F;nova_ceph.yaml \</span><br><span class="line">      --set bootstrap.wait_for_computes.enabled&#x3D;true \</span><br><span class="line">      --set conf.nova.libvirt.virt_type&#x3D;qemu \</span><br><span class="line">      --set conf.nova.libvirt.cpu_mode&#x3D;none \</span><br><span class="line">      --set conf.nova.vnc.novncproxy_base_url&#x3D;&quot;http:&#x2F;&#x2F;$&#123;APISERVER_VIP&#125;&#x2F;vnc_auto.html&quot; \</span><br><span class="line">      --timeout 1800s</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">#NOTE: Deploy placement</span><br><span class="line">helm upgrade --install placement chartmuseum&#x2F;placement \</span><br><span class="line">    --namespace&#x3D;openstack --timeout 1800s</span><br><span class="line"></span><br><span class="line">#NOTE: Deploy neutron</span><br><span class="line"></span><br><span class="line"># &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;注意&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">PUBLIC_NET_NIC&#x3D;eth0 # 设置public网络的桥接网卡</span><br><span class="line"># 指定物理网卡或桥接网络，本例中只有一张网卡，同时作为private和public，注意，一张网卡时不能指定为eth0，eth0被桥接后不带地址！！</span><br><span class="line">PRIVATE_NET_NIC&#x3D;br-ex # 设置private业务网网卡</span><br><span class="line">GATEWAY&#x3D;10.10.1.1 # 设置外部网关</span><br><span class="line"># &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;注意&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line"></span><br><span class="line">tee &#x2F;tmp&#x2F;neutron.yaml &lt;&lt; EOF</span><br><span class="line">custom_share_l3_gateway: &quot;$GATEWAY&quot;</span><br><span class="line">network:</span><br><span class="line">  interface:</span><br><span class="line">    tunnel: br-ex</span><br><span class="line">pod:</span><br><span class="line">  replicas:</span><br><span class="line">    server: 2</span><br><span class="line">conf:</span><br><span class="line">  auto_bridge_add:</span><br><span class="line">    br-ex: $PUBLIC_NET_NIC</span><br><span class="line">  neutron:</span><br><span class="line">    DEFAULT:</span><br><span class="line">      l3_ha: False</span><br><span class="line">      max_l3_agents_per_router: 1</span><br><span class="line">      l3_ha_network_type: vxlan</span><br><span class="line">      dhcp_agents_per_network: 1</span><br><span class="line">  plugins:</span><br><span class="line">    ml2_conf:</span><br><span class="line">      ml2_type_flat:</span><br><span class="line">        flat_networks: public</span><br><span class="line">    openvswitch_agent:</span><br><span class="line">      agent:</span><br><span class="line">        tunnel_types: vxlan</span><br><span class="line">      ovs:</span><br><span class="line">        bridge_mappings: public:br-ex</span><br><span class="line">    linuxbridge_agent:</span><br><span class="line">      linux_bridge:</span><br><span class="line">        bridge_mappings: public:br-ex</span><br><span class="line">EOF</span><br><span class="line">helm upgrade --install neutron chartmuseum&#x2F;neutron \</span><br><span class="line">    --namespace&#x3D;openstack \</span><br><span class="line">    --values&#x3D;&#x2F;tmp&#x2F;neutron.yaml --timeout 1800s</span><br><span class="line"></span><br><span class="line">sleep 180s</span><br><span class="line"></span><br><span class="line">kubectl get pod -n openstack |grep ovs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 等待所有pod启动完成</span><br><span class="line">kubectl get pod -n openstack |grep -v Running |grep -v Completed</span><br><span class="line"></span><br><span class="line"># 验证</span><br><span class="line">export OS_CLOUD&#x3D;openstack_helm</span><br><span class="line">[root@knode1 ~]# openstack service list</span><br><span class="line"></span><br><span class="line">+----------------------------------+-----------+-----------+</span><br><span class="line">| ID                               | Name      | Type      |</span><br><span class="line">+----------------------------------+-----------+-----------+</span><br><span class="line">| 4b8e84c1b0964d858b9c64291c06e79e | cinder    | volumev3  |</span><br><span class="line">| 524d333166fe41359178ffbd4e6c216e | keystone  | identity  |</span><br><span class="line">| 53549bf12e134837a9fb8606a5c1a027 | placement | placement |</span><br><span class="line">| 68a103d3bfde490da4be9c66b09717cb | neutron   | network   |</span><br><span class="line">| 9362ca20a79b469aa76b874dc2e06c3b | glance    | image     |</span><br><span class="line">| c695d0d4ca5b463fbfb6b8e7379f459e | nova      | compute   |</span><br><span class="line">+----------------------------------+-----------+-----------+</span><br><span class="line">[root@knode1 ~]# openstack compute service list</span><br><span class="line">+----+----------------+---------------------------------+----------+---------+-------+----------------------------+</span><br><span class="line">| ID | Binary         | Host                            | Zone     | Status  | State | Updated At                 |</span><br><span class="line">+----+----------------+---------------------------------+----------+---------+-------+----------------------------+</span><br><span class="line">|  4 | nova-scheduler | nova-scheduler-69cbb6b779-59b28 | internal | enabled | up    | 2022-05-13T14:55:04.000000 |</span><br><span class="line">|  9 | nova-conductor | nova-conductor-6477bc8d6c-zbrw2 | internal | enabled | up    | 2022-05-13T14:54:57.000000 |</span><br><span class="line">| 12 | nova-conductor | nova-conductor-6477bc8d6c-rvwrq | internal | enabled | up    | 2022-05-13T14:55:02.000000 |</span><br><span class="line">| 18 | nova-compute   | knode1                          | nova     | enabled | up    | 2022-05-13T14:54:57.000000 |</span><br><span class="line">| 20 | nova-compute   | knode3                          | nova     | enabled | up    | 2022-05-13T14:55:02.000000 |</span><br><span class="line">| 21 | nova-compute   | knode2                          | nova     | enabled | up    | 2022-05-13T14:55:00.000000 |</span><br><span class="line">| 23 | nova-compute   | knode4                          | nova     | enabled | up    | 2022-05-13T14:55:00.000000 |</span><br><span class="line">+----+----------------+---------------------------------+----------+---------+-------+----------------------------+</span><br><span class="line">[root@knode1 ~]# openstack network agent list</span><br><span class="line">+--------------------------------------+--------------------+--------+-------------------+-------+-------+---------------------------+</span><br><span class="line">| ID                                   | Agent Type         | Host   | Availability Zone | Alive | State | Binary                    |</span><br><span class="line">+--------------------------------------+--------------------+--------+-------------------+-------+-------+---------------------------+</span><br><span class="line">| 0c2397e8-0afd-47a7-a554-b67b089e1adf | Metadata agent     | knode3 | None              | :-)   | UP    | neutron-metadata-agent    |</span><br><span class="line">| 327e1437-0963-4990-8009-3ecb259d3c80 | DHCP agent         | knode2 | nova              | :-)   | UP    | neutron-dhcp-agent        |</span><br><span class="line">| 3b554200-02ec-41d5-81da-ea05741337e6 | Metadata agent     | knode1 | None              | :-)   | UP    | neutron-metadata-agent    |</span><br><span class="line">| 55ed67d8-77dd-4192-8022-48f9c7e26969 | DHCP agent         | knode1 | nova              | :-)   | UP    | neutron-dhcp-agent        |</span><br><span class="line">| 624755f4-8031-4b5d-830f-6c2ec656b111 | Metadata agent     | knode2 | None              | :-)   | UP    | neutron-metadata-agent    |</span><br><span class="line">| 8e1f1825-7ab5-4589-8c43-81e2395c6fe8 | Open vSwitch agent | knode1 | None              | :-)   | UP    | neutron-openvswitch-agent |</span><br><span class="line">| 8f6af6dc-4eac-4a9f-8c46-b8ad1c3bd64e | Open vSwitch agent | knode3 | None              | :-)   | UP    | neutron-openvswitch-agent |</span><br><span class="line">| 9a1d6634-cb30-4011-92cb-9e07ae981d05 | L3 agent           | knode2 | nova              | :-)   | UP    | neutron-l3-agent          |</span><br><span class="line">| bf372b1f-4b01-4fa4-8309-9d6975bb8373 | L3 agent           | knode1 | nova              | :-)   | UP    | neutron-l3-agent          |</span><br><span class="line">| c8073699-e64f-4dea-b1f4-a82d2f97c46e | DHCP agent         | knode3 | nova              | :-)   | UP    | neutron-dhcp-agent        |</span><br><span class="line">| ce01381b-0843-4af8-bf10-d443dded980e | Open vSwitch agent | knode4 | None              | :-)   | UP    | neutron-openvswitch-agent |</span><br><span class="line">| d9f47dc5-22d5-4556-b1eb-7e9c8a0c7282 | L3 agent           | knode3 | nova              | :-)   | UP    | neutron-l3-agent          |</span><br><span class="line">| ee1d334d-88c3-45c1-83aa-c6bd08449d2d | Open vSwitch agent | knode2 | None              | :-)   | UP    | neutron-openvswitch-agent |</span><br><span class="line">+--------------------------------------+--------------------+--------+-------------------+-------+-------+---------------------------+</span><br><span class="line">[root@knode1 ~]# openstack hypervisor list</span><br><span class="line">+----+---------------------+-----------------+-------------+-------+</span><br><span class="line">| ID | Hypervisor Hostname | Hypervisor Type | Host IP     | State |</span><br><span class="line">+----+---------------------+-----------------+-------------+-------+</span><br><span class="line">|  2 | knode1              | QEMU            | 10.10.1.100 | up    |</span><br><span class="line">|  5 | knode3              | QEMU            | 10.10.1.120 | up    |</span><br><span class="line">|  8 | knode2              | QEMU            | 10.10.1.110 | up    |</span><br><span class="line">|  9 | knode4              | QEMU            | 10.10.1.130 | up    |</span><br><span class="line">+----+---------------------+-----------------+-------------+-------+</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 在所有节点添加默认路由，避免重启后丢失</span><br><span class="line">ip route | grep default || ip route add default via $GATEWAY dev br-ex</span><br><span class="line">echo &quot;ip route | grep default || ip route add default via $GATEWAY dev br-ex&quot; &gt;&gt; &#x2F;etc&#x2F;rc.local</span><br></pre></td></tr></table></figure><p>7.安装heat</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">helm upgrade --install heat chartmuseum&#x2F;heat \</span><br><span class="line">  --namespace&#x3D;openstack</span><br><span class="line"></span><br><span class="line"># 验证</span><br><span class="line">export OS_CLOUD&#x3D;openstack_helm</span><br><span class="line">openstack service list</span><br><span class="line">openstack endpoint list</span><br><span class="line"></span><br><span class="line">openstack --os-interface public orchestration service list</span><br><span class="line">+------------------------------+-------------+--------------------------------------+-------------+--------+----------------------------+--------+</span><br><span class="line">| Hostname                     | Binary      | Engine ID                            | Host        | Topic  | Updated At                 | Status |</span><br><span class="line">+------------------------------+-------------+--------------------------------------+-------------+--------+----------------------------+--------+</span><br><span class="line">| heat-engine-5bc7886f47-vps7v | heat-engine | df962df7-3829-4bff-8c77-3df5b7cadd49 | heat-engine | engine | 2022-05-13T15:11:50.000000 | up     |</span><br><span class="line">| heat-engine-5bc7886f47-khr52 | heat-engine | 5358bba9-aa70-4bb2-be57-25138763dd16 | heat-engine | engine | 2022-05-13T15:11:51.000000 | up     |</span><br><span class="line">+------------------------------+-------------+--------------------------------------+-------------+--------+----------------------------+--------+</span><br></pre></td></tr></table></figure><p>8.安装horizon（可选）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">helm upgrade --install horizon chartmuseum&#x2F;horizon \</span><br><span class="line">  --namespace&#x3D;openstack</span><br><span class="line"># 检查pod启动</span><br><span class="line">kubectl  get pod -n openstack -owide|grep -v Run|grep -v Com</span><br></pre></td></tr></table></figure><h1 id="五-注意事项"><a href="#五-注意事项" class="headerlink" title="五.注意事项"></a>五.注意事项</h1><p><strong>1.步骤中wait方式等待可能会不准确，即pod未就绪，但deploy状态已就绪，需要确认pod处于Running后，再进行对应验证操作，否则会失败</strong></p><p><strong>2.在placement安装过程中，nova相关组件可能会出现认证错误，在neutron完成安装并启动完成前可以忽视这些错误</strong></p><p><strong>3.在db sync过程中，可能由于DB锁未释放等问题，产生死锁，但是db-sync 或init pod crash，可以忽略，等待后会自动恢复</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;节点名&lt;/th&gt;
&lt;th&gt;角色&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;knode1&lt;/td&gt;
&lt;td&gt;融合节点&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;knode2&lt;/td&gt;
&lt;td&gt;融合节点&lt;/</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>kubeadm部署生产k8s</title>
    <link href="http://example.com/2022/04/15/kubeadm%E9%83%A8%E7%BD%B2%E7%94%9F%E4%BA%A7k8s/"/>
    <id>http://example.com/2022/04/15/kubeadm%E9%83%A8%E7%BD%B2%E7%94%9F%E4%BA%A7k8s/</id>
    <published>2022-04-15T07:59:59.000Z</published>
    <updated>2022-05-16T06:14:58.013Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一-环境准备"><a href="#一-环境准备" class="headerlink" title="一.环境准备"></a>一.环境准备</h1><table><thead><tr><th>IP</th><th>主机名/类型</th><th>ApiServer端口号</th></tr></thead><tbody><tr><td>192.168.122.213</td><td>knode1</td><td>6443</td></tr><tr><td>192.168.122.74</td><td>knode2</td><td>6443</td></tr><tr><td>192.168.122.18</td><td>knode3</td><td>6443</td></tr><tr><td>192.168.122.150</td><td>VIP</td><td>7443</td></tr></tbody></table><p>1.基础参数配置（所有节点）</p><p>设置主机名：</p><p><code>hostnamectl set-hostname node1</code></p><p>生成密钥、免密登陆：</p><p><code>ssh-keygen</code>，<code>ssh-copy-id</code> </p><p>关闭防火墙：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br></pre></td></tr></table></figure><p>加载 <code>br_netfilter</code> 模块  ，设置桥接。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">sudo modprobe br_netfilter</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;<span class="string">EOF | sudo tee /etc/modules-load.d/k8s.conf</span></span><br><span class="line"><span class="string">br_netfilter</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">cat &lt;&lt;<span class="string">EOF | sudo tee /etc/sysctl.d/k8s.conf</span></span><br><span class="line"><span class="string">net.bridge.bridge-nf-call-ip6tables = 1</span></span><br><span class="line"><span class="string">net.bridge.bridge-nf-call-iptables = 1</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">sudo sysctl --system</span><br></pre></td></tr></table></figure><p>2.安装并配置docker（所有节点）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">sudo yum remove docker                   docker-client                   docker-client-latest                   docker-common                   docker-latest                   docker-latest-logrotate                   docker-logrotate                   docker-engine</span><br><span class="line">sudo yum install -y yum-utils</span><br><span class="line">sudo yum-config-manager     --add-repo     https:&#x2F;&#x2F;download.docker.com&#x2F;linux&#x2F;centos&#x2F;docker-ce.repo</span><br><span class="line">sudo yum install -y docker-ce docker-ce-cli containerd.io</span><br><span class="line">sudo mkdir &#x2F;etc&#x2F;docker</span><br><span class="line">cat &lt;&lt;EOF | sudo tee &#x2F;etc&#x2F;docker&#x2F;daemon.json</span><br><span class="line">&#123;</span><br><span class="line">  &quot;exec-opts&quot;: [&quot;native.cgroupdriver&#x3D;systemd&quot;],</span><br><span class="line">  &quot;log-driver&quot;: &quot;json-file&quot;,</span><br><span class="line">  &quot;log-opts&quot;: &#123;</span><br><span class="line">    &quot;max-size&quot;: &quot;100m&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;storage-driver&quot;: &quot;overlay2&quot;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sudo systemctl enable docker</span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl restart docker</span><br></pre></td></tr></table></figure><h1 id="二-通过kubeadm部署融合生产环境（3节点）"><a href="#二-通过kubeadm部署融合生产环境（3节点）" class="headerlink" title="二.通过kubeadm部署融合生产环境（3节点）"></a>二.通过kubeadm部署融合生产环境（3节点）</h1><p>1.安装kubeadm（所有节点）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF | sudo tee &#x2F;etc&#x2F;yum.repos.d&#x2F;kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name&#x3D;Kubernetes</span><br><span class="line">baseurl&#x3D;https:&#x2F;&#x2F;packages.cloud.google.com&#x2F;yum&#x2F;repos&#x2F;kubernetes-el7-\$basearch</span><br><span class="line">enabled&#x3D;1</span><br><span class="line">gpgcheck&#x3D;0</span><br><span class="line">repo_gpgcheck&#x3D;0</span><br><span class="line">gpgkey&#x3D;https:&#x2F;&#x2F;packages.cloud.google.com&#x2F;yum&#x2F;doc&#x2F;yum-key.gpg https:&#x2F;&#x2F;packages.cloud.google.com&#x2F;yum&#x2F;doc&#x2F;rpm-package-key.gpg</span><br><span class="line">exclude&#x3D;kubelet kubeadm kubectl</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 将 SELinux 设置为 permissive 模式（相当于将其禁用）</span><br><span class="line">sudo setenforce 0</span><br><span class="line">sudo sed -i &#39;s&#x2F;^SELINUX&#x3D;enforcing$&#x2F;SELINUX&#x3D;permissive&#x2F;&#39; &#x2F;etc&#x2F;selinux&#x2F;config</span><br><span class="line"></span><br><span class="line">sudo yum install -y kubelet kubeadm kubectl --disableexcludes&#x3D;kubernetes</span><br><span class="line"></span><br><span class="line">sudo systemctl enable --now kubelet</span><br></pre></td></tr></table></figure><p>2.初始化环境变量（所有节点）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">APISERVER_VIP&#x3D;192.168.122.150</span><br><span class="line"></span><br><span class="line">APISERVER_DEST_PORT&#x3D;7443</span><br><span class="line"></span><br><span class="line">APISERVER_SRC_PORT&#x3D;6443</span><br><span class="line"></span><br><span class="line">HOST1_ID&#x3D;knode1</span><br><span class="line"></span><br><span class="line">HOST1_ADDRESS&#x3D;192.168.122.213</span><br><span class="line"></span><br><span class="line">HOST2_ID&#x3D;knode2</span><br><span class="line"></span><br><span class="line">HOST2_ADDRESS&#x3D;192.168.122.74</span><br><span class="line"></span><br><span class="line">HOST3_ID&#x3D;knode3</span><br><span class="line"></span><br><span class="line">HOST3_ADDRESS&#x3D;192.168.122.18</span><br></pre></td></tr></table></figure><p>3.为kube-api配置负载均衡（keepalive+haproxy）（所有控制节点）</p><p>keepalive&amp; haproxy配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line">########### keepalived ###########</span><br><span class="line">sudo yum install -y keepalived</span><br><span class="line">sudo cat &lt;&lt;EOF | sudo tee &#x2F;etc&#x2F;keepalived&#x2F;keepalived.conf</span><br><span class="line">global_defs &#123;</span><br><span class="line">    router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line">vrrp_script check_apiserver &#123;</span><br><span class="line">  script &quot;&#x2F;etc&#x2F;keepalived&#x2F;check_apiserver.sh&quot;</span><br><span class="line">  interval 3</span><br><span class="line">  weight -2</span><br><span class="line">  fall 10</span><br><span class="line">  rise 2</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER</span><br><span class="line">    interface eth0</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 100</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 42</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        $&#123;APISERVER_VIP&#125; # VIP地址</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">        check_apiserver</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sudo cat &lt;&lt;EOF | sudo tee &#x2F;etc&#x2F;keepalived&#x2F;check_apiserver.sh</span><br><span class="line">#!&#x2F;bin&#x2F;sh</span><br><span class="line"></span><br><span class="line">errorExit() &#123;</span><br><span class="line">    echo &quot;*** $*&quot; 1&gt;&amp;2</span><br><span class="line">    exit 1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">curl --silent --max-time 2 --insecure https:&#x2F;&#x2F;localhost:$&#123;APISERVER_DEST_PORT&#125;&#x2F; -o &#x2F;dev&#x2F;null || errorExit &quot;Error GET https:&#x2F;&#x2F;localhost:$&#123;APISERVER_DEST_PORT&#125;&#x2F;&quot;</span><br><span class="line">if ip addr | grep -q $&#123;APISERVER_VIP&#125;; then</span><br><span class="line">    curl --silent --max-time 2 --insecure https:&#x2F;&#x2F;$&#123;APISERVER_VIP&#125;:$&#123;APISERVER_DEST_PORT&#125;&#x2F; -o &#x2F;dev&#x2F;null || errorExit &quot;Error GET https:&#x2F;&#x2F;$&#123;APISERVER_VIP&#125;:$&#123;APISERVER_DEST_PORT&#125;&#x2F;&quot;</span><br><span class="line">fi</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">########### haproxy ###########</span><br><span class="line">sudo yum install -y haproxy</span><br><span class="line">sudo cat &lt;&lt;EOF | sudo tee &#x2F;etc&#x2F;haproxy&#x2F;haproxy.cfg</span><br><span class="line"># &#x2F;etc&#x2F;haproxy&#x2F;haproxy.cfg</span><br><span class="line">#---------------------------------------------------------------------</span><br><span class="line"># Global settings</span><br><span class="line">#---------------------------------------------------------------------</span><br><span class="line">global</span><br><span class="line">    log &#x2F;dev&#x2F;log local0</span><br><span class="line">    log &#x2F;dev&#x2F;log local1 notice</span><br><span class="line">    daemon</span><br><span class="line"></span><br><span class="line">#---------------------------------------------------------------------</span><br><span class="line"># common defaults that all the &#39;listen&#39; and &#39;backend&#39; sections will</span><br><span class="line"># use if not designated in their block</span><br><span class="line">#---------------------------------------------------------------------</span><br><span class="line">defaults</span><br><span class="line">    mode                    http</span><br><span class="line">    log                     global</span><br><span class="line">    option                  httplog</span><br><span class="line">    option                  dontlognull</span><br><span class="line">    option http-server-close</span><br><span class="line">    option forwardfor       except 127.0.0.0&#x2F;8</span><br><span class="line">    option                  redispatch</span><br><span class="line">    retries                 1</span><br><span class="line">    timeout http-request    10s</span><br><span class="line">    timeout queue           20s</span><br><span class="line">    timeout connect         5s</span><br><span class="line">    timeout client          20s</span><br><span class="line">    timeout server          20s</span><br><span class="line">    timeout http-keep-alive 10s</span><br><span class="line">    timeout check           10s</span><br><span class="line"></span><br><span class="line">#---------------------------------------------------------------------</span><br><span class="line"># apiserver frontend which proxys to the control plane nodes</span><br><span class="line">#---------------------------------------------------------------------</span><br><span class="line">frontend apiserver</span><br><span class="line">    bind *:$&#123;APISERVER_DEST_PORT&#125;</span><br><span class="line">    mode tcp</span><br><span class="line">    option tcplog</span><br><span class="line">    default_backend apiserver</span><br><span class="line"></span><br><span class="line">#---------------------------------------------------------------------</span><br><span class="line"># round robin balancing for apiserver</span><br><span class="line">#---------------------------------------------------------------------</span><br><span class="line">backend apiserver</span><br><span class="line">    option httpchk GET &#x2F;healthz</span><br><span class="line">    http-check expect status 200</span><br><span class="line">    mode tcp</span><br><span class="line">    option ssl-hello-chk</span><br><span class="line">    balance     roundrobin</span><br><span class="line">        server $&#123;HOST1_ID&#125; $&#123;HOST1_ADDRESS&#125;:$&#123;APISERVER_SRC_PORT&#125; check</span><br><span class="line">        server $&#123;HOST2_ID&#125; $&#123;HOST2_ADDRESS&#125;:$&#123;APISERVER_SRC_PORT&#125; check</span><br><span class="line">        server $&#123;HOST3_ID&#125; $&#123;HOST3_ADDRESS&#125;:$&#123;APISERVER_SRC_PORT&#125; check</span><br><span class="line">EOF</span><br><span class="line">systemctl enable haproxy --now</span><br><span class="line">systemctl enable keepalived --now</span><br></pre></td></tr></table></figure><p>4.初始化控制平面（第一个控制节点）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">########### init first control ###########</span><br><span class="line"></span><br><span class="line">sudo kubeadm init --control-plane-endpoint &quot;$&#123;APISERVER_VIP&#125;:$&#123;APISERVER_DEST_PORT&#125;&quot; --upload-certs  --pod-network-cidr&#x3D;10.244.0.0&#x2F;16 --kubernetes-version 1.23.5</span><br><span class="line">mkdir -p $HOME&#x2F;.kube</span><br><span class="line">sudo cp -i &#x2F;etc&#x2F;kubernetes&#x2F;admin.conf $HOME&#x2F;.kube&#x2F;config</span><br><span class="line">sudo chown $(id -u):$(id -g) $HOME&#x2F;.kube&#x2F;config</span><br></pre></td></tr></table></figure><p>5.安装flannel网络插件（vxlan）（第一个控制节点）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br></pre></td><td class="code"><pre><span class="line">sudo cat &lt;&lt;EOF | sudo tee &#x2F;tmp&#x2F;flannel.yaml</span><br><span class="line">---</span><br><span class="line">apiVersion: policy&#x2F;v1beta1</span><br><span class="line">kind: PodSecurityPolicy</span><br><span class="line">metadata:</span><br><span class="line">  name: psp.flannel.unprivileged</span><br><span class="line">  annotations:</span><br><span class="line">    seccomp.security.alpha.kubernetes.io&#x2F;allowedProfileNames: docker&#x2F;default</span><br><span class="line">    seccomp.security.alpha.kubernetes.io&#x2F;defaultProfileName: docker&#x2F;default</span><br><span class="line">    apparmor.security.beta.kubernetes.io&#x2F;allowedProfileNames: runtime&#x2F;default</span><br><span class="line">    apparmor.security.beta.kubernetes.io&#x2F;defaultProfileName: runtime&#x2F;default</span><br><span class="line">spec:</span><br><span class="line">  privileged: false</span><br><span class="line">  volumes:</span><br><span class="line">  - configMap</span><br><span class="line">  - secret</span><br><span class="line">  - emptyDir</span><br><span class="line">  - hostPath</span><br><span class="line">  allowedHostPaths:</span><br><span class="line">  - pathPrefix: &quot;&#x2F;etc&#x2F;cni&#x2F;net.d&quot;</span><br><span class="line">  - pathPrefix: &quot;&#x2F;etc&#x2F;kube-flannel&quot;</span><br><span class="line">  - pathPrefix: &quot;&#x2F;run&#x2F;flannel&quot;</span><br><span class="line">  readOnlyRootFilesystem: false</span><br><span class="line">  # Users and groups</span><br><span class="line">  runAsUser:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  supplementalGroups:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  fsGroup:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  # Privilege Escalation</span><br><span class="line">  allowPrivilegeEscalation: false</span><br><span class="line">  defaultAllowPrivilegeEscalation: false</span><br><span class="line">  # Capabilities</span><br><span class="line">  allowedCapabilities: [&#39;NET_ADMIN&#39;, &#39;NET_RAW&#39;]</span><br><span class="line">  defaultAddCapabilities: []</span><br><span class="line">  requiredDropCapabilities: []</span><br><span class="line">  # Host namespaces</span><br><span class="line">  hostPID: false</span><br><span class="line">  hostIPC: false</span><br><span class="line">  hostNetwork: true</span><br><span class="line">  hostPorts:</span><br><span class="line">  - min: 0</span><br><span class="line">    max: 65535</span><br><span class="line">  # SELinux</span><br><span class="line">  seLinux:</span><br><span class="line">    # SELinux is unused in CaaSP</span><br><span class="line">    rule: &#39;RunAsAny&#39;</span><br><span class="line">---</span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1</span><br><span class="line">metadata:</span><br><span class="line">  name: flannel</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [&#39;extensions&#39;]</span><br><span class="line">  resources: [&#39;podsecuritypolicies&#39;]</span><br><span class="line">  verbs: [&#39;use&#39;]</span><br><span class="line">  resourceNames: [&#39;psp.flannel.unprivileged&#39;]</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &quot;&quot;</span><br><span class="line">  resources:</span><br><span class="line">  - pods</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &quot;&quot;</span><br><span class="line">  resources:</span><br><span class="line">  - nodes</span><br><span class="line">  verbs:</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &quot;&quot;</span><br><span class="line">  resources:</span><br><span class="line">  - nodes&#x2F;status</span><br><span class="line">  verbs:</span><br><span class="line">  - patch</span><br><span class="line">---</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1</span><br><span class="line">metadata:</span><br><span class="line">  name: flannel</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: flannel</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: flannel</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: flannel</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">kind: ConfigMap</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-flannel-cfg</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    tier: node</span><br><span class="line">    app: flannel</span><br><span class="line">data:</span><br><span class="line">  cni-conf.json: |</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;name&quot;: &quot;cbr0&quot;,</span><br><span class="line">      &quot;cniVersion&quot;: &quot;0.3.1&quot;,</span><br><span class="line">      &quot;plugins&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;type&quot;: &quot;flannel&quot;,</span><br><span class="line">          &quot;delegate&quot;: &#123;</span><br><span class="line">            &quot;hairpinMode&quot;: true,</span><br><span class="line">            &quot;isDefaultGateway&quot;: true</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;type&quot;: &quot;portmap&quot;,</span><br><span class="line">          &quot;capabilities&quot;: &#123;</span><br><span class="line">            &quot;portMappings&quot;: true</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  net-conf.json: |</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;Network&quot;: &quot;10.244.0.0&#x2F;16&quot;,</span><br><span class="line">      &quot;Backend&quot;: &#123;</span><br><span class="line">        &quot;Type&quot;: &quot;vxlan&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">---</span><br><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-flannel-ds</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    tier: node</span><br><span class="line">    app: flannel</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: flannel</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        tier: node</span><br><span class="line">        app: flannel</span><br><span class="line">    spec:</span><br><span class="line">      affinity:</span><br><span class="line">        nodeAffinity:</span><br><span class="line">          requiredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">            nodeSelectorTerms:</span><br><span class="line">            - matchExpressions:</span><br><span class="line">              - key: kubernetes.io&#x2F;os</span><br><span class="line">                operator: In</span><br><span class="line">                values:</span><br><span class="line">                - linux</span><br><span class="line">      hostNetwork: true</span><br><span class="line">      priorityClassName: system-node-critical</span><br><span class="line">      tolerations:</span><br><span class="line">      - operator: Exists</span><br><span class="line">        effect: NoSchedule</span><br><span class="line">      serviceAccountName: flannel</span><br><span class="line">      initContainers:</span><br><span class="line">      - name: install-cni-plugin</span><br><span class="line">       #image: flannelcni&#x2F;flannel-cni-plugin:v1.0.1 for ppc64le and mips64le (dockerhub limitations may apply)</span><br><span class="line">        image: rancher&#x2F;mirrored-flannelcni-flannel-cni-plugin:v1.0.1</span><br><span class="line">        command:</span><br><span class="line">        - cp</span><br><span class="line">        args:</span><br><span class="line">        - -f</span><br><span class="line">        - &#x2F;flannel</span><br><span class="line">        - &#x2F;opt&#x2F;cni&#x2F;bin&#x2F;flannel</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: cni-plugin</span><br><span class="line">          mountPath: &#x2F;opt&#x2F;cni&#x2F;bin</span><br><span class="line">      - name: install-cni</span><br><span class="line">       #image: flannelcni&#x2F;flannel:v0.17.0 for ppc64le and mips64le (dockerhub limitations may apply)</span><br><span class="line">        image: rancher&#x2F;mirrored-flannelcni-flannel:v0.17.0</span><br><span class="line">        command:</span><br><span class="line">        - cp</span><br><span class="line">        args:</span><br><span class="line">        - -f</span><br><span class="line">        - &#x2F;etc&#x2F;kube-flannel&#x2F;cni-conf.json</span><br><span class="line">        - &#x2F;etc&#x2F;cni&#x2F;net.d&#x2F;10-flannel.conflist</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: cni</span><br><span class="line">          mountPath: &#x2F;etc&#x2F;cni&#x2F;net.d</span><br><span class="line">        - name: flannel-cfg</span><br><span class="line">          mountPath: &#x2F;etc&#x2F;kube-flannel&#x2F;</span><br><span class="line">      containers:</span><br><span class="line">      - name: kube-flannel</span><br><span class="line">       #image: flannelcni&#x2F;flannel:v0.17.0 for ppc64le and mips64le (dockerhub limitations may apply)</span><br><span class="line">        image: rancher&#x2F;mirrored-flannelcni-flannel:v0.17.0</span><br><span class="line">        command:</span><br><span class="line">        - &#x2F;opt&#x2F;bin&#x2F;flanneld</span><br><span class="line">        args:</span><br><span class="line">        - --ip-masq</span><br><span class="line">        - --kube-subnet-mgr</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            cpu: &quot;100m&quot;</span><br><span class="line">            memory: &quot;50Mi&quot;</span><br><span class="line">          limits:</span><br><span class="line">            cpu: &quot;100m&quot;</span><br><span class="line">            memory: &quot;50Mi&quot;</span><br><span class="line">        securityContext:</span><br><span class="line">          privileged: false</span><br><span class="line">          capabilities:</span><br><span class="line">            add: [&quot;NET_ADMIN&quot;, &quot;NET_RAW&quot;]</span><br><span class="line">        env:</span><br><span class="line">        - name: POD_NAME</span><br><span class="line">          valueFrom:</span><br><span class="line">            fieldRef:</span><br><span class="line">              fieldPath: metadata.name</span><br><span class="line">        - name: POD_NAMESPACE</span><br><span class="line">          valueFrom:</span><br><span class="line">            fieldRef:</span><br><span class="line">              fieldPath: metadata.namespace</span><br><span class="line">        - name: EVENT_QUEUE_DEPTH</span><br><span class="line">          value: &quot;5000&quot;</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: run</span><br><span class="line">          mountPath: &#x2F;run&#x2F;flannel</span><br><span class="line">        - name: flannel-cfg</span><br><span class="line">          mountPath: &#x2F;etc&#x2F;kube-flannel&#x2F;</span><br><span class="line">        - name: xtables-lock</span><br><span class="line">          mountPath: &#x2F;run&#x2F;xtables.lock</span><br><span class="line">      volumes:</span><br><span class="line">      - name: run</span><br><span class="line">        hostPath:</span><br><span class="line">          path: &#x2F;run&#x2F;flannel</span><br><span class="line">      - name: cni-plugin</span><br><span class="line">        hostPath:</span><br><span class="line">          path: &#x2F;opt&#x2F;cni&#x2F;bin</span><br><span class="line">      - name: cni</span><br><span class="line">        hostPath:</span><br><span class="line">          path: &#x2F;etc&#x2F;cni&#x2F;net.d</span><br><span class="line">      - name: flannel-cfg</span><br><span class="line">        configMap:</span><br><span class="line">          name: kube-flannel-cfg</span><br><span class="line">      - name: xtables-lock</span><br><span class="line">        hostPath:</span><br><span class="line">          path: &#x2F;run&#x2F;xtables.lock</span><br><span class="line">          type: FileOrCreate</span><br><span class="line">EOF</span><br><span class="line">kubectl  apply -f &#x2F;tmp&#x2F;flannel.yaml</span><br></pre></td></tr></table></figure><p>6.添加额外的控制节点</p><p>查看第一个控制节点状态：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@knode1 ~]# kubectl get pod -n kube-system -w</span><br><span class="line">NAME                             READY   STATUS    RESTARTS   AGE</span><br><span class="line">coredns-64897985d-4hjxc          1&#x2F;1     Running   0          2m6s</span><br><span class="line">coredns-64897985d-9x4lz          1&#x2F;1     Running   0          2m6s</span><br><span class="line">etcd-knode1                      1&#x2F;1     Running   1          2m15s</span><br><span class="line">kube-apiserver-knode1            1&#x2F;1     Running   1          2m15s</span><br><span class="line">kube-controller-manager-knode1   1&#x2F;1     Running   0          2m14s</span><br><span class="line">kube-flannel-ds-v45xx            1&#x2F;1     Running   0          45s</span><br><span class="line">kube-proxy-b55jc                 1&#x2F;1     Running   0          2m6s</span><br><span class="line">kube-scheduler-knode1            1&#x2F;1     Running   1          2m15s</span><br></pre></td></tr></table></figure><p>获取密钥信息（在第一个控制节点执行）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">FIRSTCONTROLNODE&#x3D;192.168.122.213</span><br><span class="line">TOKEN&#x3D;&#96;kubeadm token create&#96;</span><br><span class="line">DISCOVERYTOKEHASH&#x3D;&#96;openssl x509 -pubkey -in &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.crt | openssl rsa -pubin -outform der 2&gt;&#x2F;dev&#x2F;null | \</span><br><span class="line">   openssl dgst -sha256 -hex | sed &#39;s&#x2F;^.* &#x2F;&#x2F;&#39;&#96;</span><br><span class="line">CERTKEY&#x3D;&#96;kubeadm init phase upload-certs --upload-certs --one-output|grep -v upload-certs&#96;</span><br></pre></td></tr></table></figure><p>加入额外控制节点（在需要加入的额外控制节点上执行）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo kubeadm join $&#123;FIRSTCONTROLNODE&#125;:6443 --token $&#123;TOKEN&#125; --discovery-token-ca-cert-hash sha256:$&#123;DISCOVERYTOKEHASH&#125; --control-plane --certificate-key $&#123;CERTKEY&#125;</span><br><span class="line">mkdir -p $HOME&#x2F;.kube</span><br><span class="line">sudo cp -i &#x2F;etc&#x2F;kubernetes&#x2F;admin.conf $HOME&#x2F;.kube&#x2F;config</span><br><span class="line">sudo chown $(id -u):$(id -g) $HOME&#x2F;.kube&#x2F;config</span><br></pre></td></tr></table></figure><p>加入额外node节点（在需要加入的额外node节点上执行）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo kubeadm join $&#123;FIRSTCONTROLNODE&#125;:6443 --token $&#123;TOKEN&#125; --discovery-token-ca-cert-hash sha256:$&#123;DISCOVERYTOKEHASH&#125;</span><br></pre></td></tr></table></figure><h1 id="三-验证"><a href="#三-验证" class="headerlink" title="三.验证"></a>三.验证</h1><p>在任意控制节点执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@knode1 ~]# kubectl  get nodes</span><br><span class="line">NAME     STATUS   ROLES                  AGE     VERSION</span><br><span class="line">knode1   Ready    control-plane,master   3m27s   v1.23.6</span><br><span class="line">knode2   Ready    control-plane,master   59s     v1.23.6</span><br><span class="line">knode3   Ready    control-plane,master   58s     v1.23.6</span><br><span class="line">knode4   Ready    &lt;none&gt;                 11s     v1.23.6</span><br></pre></td></tr></table></figure><h1 id="四-离线部署"><a href="#四-离线部署" class="headerlink" title="四.离线部署"></a>四.离线部署</h1><p>1.如果联机部署需要配置代理访问，包括镜像源和yum源代理，如果本地离线部署，需要提前准备好本地镜像仓库与本地yum源：</p><p>kubernetes yum源参考：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[kubernetes]</span><br><span class="line">name&#x3D;Kubernetes</span><br><span class="line">baseurl&#x3D;https:&#x2F;&#x2F;packages.cloud.google.com&#x2F;yum&#x2F;repos&#x2F;kubernetes-el7-$basearch</span><br><span class="line">enabled&#x3D;1</span><br><span class="line">gpgcheck&#x3D;0</span><br><span class="line">repo_gpgcheck&#x3D;0</span><br><span class="line">gpgkey&#x3D;https:&#x2F;&#x2F;packages.cloud.google.com&#x2F;yum&#x2F;doc&#x2F;yum-key.gpg https:&#x2F;&#x2F;packages.cloud.google.com&#x2F;yum&#x2F;doc&#x2F;rpm-package-key.gpg</span><br><span class="line">exclude&#x3D;kubelet kubeadm kubectl</span><br><span class="line">proxy&#x3D;http:&#x2F;&#x2F;knode1:8090</span><br></pre></td></tr></table></figure><p>下载离线镜像：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubeadm config images list</span><br><span class="line">kubeadm config images pull</span><br><span class="line">docker pull rancher&#x2F;mirrored-flannelcni-flannel:v0.17.0</span><br><span class="line">docker pull rancher&#x2F;mirrored-flannelcni-flannel-cni-plugin:v1.0.1</span><br></pre></td></tr></table></figure><p>2.打包镜像</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">IMAGES_LIST&#x3D;($(docker  images   | sed  &#39;1d&#39; | awk  &#39;&#123;print $1&quot;:&quot;$2&#125;&#39;))</span><br><span class="line">docker save $&#123;IMAGES_LIST[*]&#125;  -o  all-images.tar.gz</span><br></pre></td></tr></table></figure><p>3.在其他节点导入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker load &lt; all-images.tar.gz</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一-环境准备&quot;&gt;&lt;a href=&quot;#一-环境准备&quot; class=&quot;headerlink&quot; title=&quot;一.环境准备&quot;&gt;&lt;/a&gt;一.环境准备&lt;/h1&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;IP&lt;/th&gt;
&lt;th&gt;主机名/类型&lt;/th&gt;
&lt;th&gt;ApiS</summary>
      
    
    
    
    
    <category term="k8s" scheme="http://example.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>一致性话题</title>
    <link href="http://example.com/2022/01/19/%E4%B8%80%E8%87%B4%E6%80%A7%E8%AF%9D%E9%A2%98/"/>
    <id>http://example.com/2022/01/19/%E4%B8%80%E8%87%B4%E6%80%A7%E8%AF%9D%E9%A2%98/</id>
    <published>2022-01-19T02:25:56.000Z</published>
    <updated>2022-01-19T02:29:29.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一致性概述"><a href="#一致性概述" class="headerlink" title="一致性概述"></a><strong>一致性概述</strong></h2><p>一致性问题是分布式中间件中必须考虑的问题之一，此篇中我们将对几种常见的一致性模型进行分析。</p><span id="more"></span><h2 id="一致性分类"><a href="#一致性分类" class="headerlink" title="一致性分类"></a>一致性分类</h2><h4 id="强一致性"><a href="#强一致性" class="headerlink" title="强一致性"></a>强一致性</h4><h4 id="弱一致性"><a href="#弱一致性" class="headerlink" title="弱一致性"></a>弱一致性</h4>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一致性概述&quot;&gt;&lt;a href=&quot;#一致性概述&quot; class=&quot;headerlink&quot; title=&quot;一致性概述&quot;&gt;&lt;/a&gt;&lt;strong&gt;一致性概述&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;一致性问题是分布式中间件中必须考虑的问题之一，此篇中我们将对几种常见的一致性模型进行分析。&lt;/p&gt;</summary>
    
    
    
    
    <category term="分布式中间件" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title>kubelet</title>
    <link href="http://example.com/2021/06/23/kubelet/"/>
    <id>http://example.com/2021/06/23/kubelet/</id>
    <published>2021-06-23T08:43:01.000Z</published>
    <updated>2021-07-13T02:51:49.380Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>garbage-collector-controller</title>
    <link href="http://example.com/2021/06/15/garbage-collector-controller/"/>
    <id>http://example.com/2021/06/15/garbage-collector-controller/</id>
    <published>2021-06-15T02:44:16.000Z</published>
    <updated>2021-07-13T02:51:49.380Z</updated>
    
    <content type="html"><![CDATA[<p>Kubernetes在删除对象时，其对应的controller并不会真正去删除对象，删除对象工作是由GarbageCollectorController负责的。</p><span id="more"></span><p>当删除一个对象时，会根据删除策略来对资源进行回收处理。</p><h3 id="K8S中的删除策略"><a href="#K8S中的删除策略" class="headerlink" title="K8S中的删除策略"></a>K8S中的删除策略</h3><p>Orphan</p><p>Foreground</p><p>Background</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Kubernetes在删除对象时，其对应的controller并不会真正去删除对象，删除对象工作是由GarbageCollectorController负责的。&lt;/p&gt;</summary>
    
    
    
    
    <category term="k8s" scheme="http://example.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>CSI plugin</title>
    <link href="http://example.com/2021/04/20/CSI-plugin/"/>
    <id>http://example.com/2021/04/20/CSI-plugin/</id>
    <published>2021-04-20T08:37:27.000Z</published>
    <updated>2021-07-13T04:59:04.240Z</updated>
    
    <content type="html"><![CDATA[<p>在了解k8s的CSI plugin编写前，我们需要先了解下有关K8S的持久化存储机制。</p><span id="more"></span><h3 id="理解k8s持久化存储"><a href="#理解k8s持久化存储" class="headerlink" title="理解k8s持久化存储"></a>理解k8s持久化存储</h3><p>在k8s中，持久化存储采用PV和PVC进行绑定的的方式进行管理。</p><p><em>PV（PersistentVolume）：</em>存储卷对象映射，一般由管理员手动创建或通过存储插件（External Provisioner）创建。示例：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pv0003</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">capacity:</span></span><br><span class="line">    <span class="attr">storage:</span> <span class="string">5Gi</span></span><br><span class="line">  <span class="attr">volumeMode:</span> <span class="string">Filesystem</span> <span class="comment"># K8S支持两种volumeMode：Filesystem和Block</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Recycle</span> <span class="comment"># 三种策略可选：Retain\Recycle\Delete，只有NFS和HostPath支持Recycle（纯调用rm -rf命令进行文件系统级别删除）</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">slow</span></span><br><span class="line">  <span class="attr">mountOptions:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">hard</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">nfsvers=4.1</span></span><br><span class="line">  <span class="attr">nfs:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/tmp</span></span><br><span class="line">    <span class="attr">server:</span> <span class="number">172.17</span><span class="number">.0</span><span class="number">.2</span></span><br></pre></td></tr></table></figure><p><em>PVC（PersistentVolumeClaim）</em>：存储卷声明，一般由开发人员定义，对于支持Dynamic Provisioning的存储类型，通过对PVC的声明（可以在pod中完成），可以让PersistentVolumeController找到一块合适的PV与PVC进行bound操作。示例：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">claim1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">fast</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">30Gi</span></span><br></pre></td></tr></table></figure><p>这种绑定操作可以是<strong>静态的（Static Provisioning）</strong>，也可以是<strong>动态的（Dynamic Provisioning）</strong></p><p>首先说静态，通过静态方式进行时，由管理员创建PV，通过PersistentVolumeController，k8s可以完成PV和PVC的绑定，PersistentVolumeController(<code>pkg/controller/volume/persistentvolume/pv_controller.go</code>)存在一个控制循环，不断遍历所有可用状态的PV，尝试与PVC进行绑定（Bound）操作，绑定成功后，则为声明该PVC的Pod提供存储服务。</p><h4 id="PV和PVC绑定调度流程："><a href="#PV和PVC绑定调度流程：" class="headerlink" title="PV和PVC绑定调度流程："></a>PV和PVC绑定调度流程：</h4><p>当PVC被声明出来时（单独声明 or statefulSet），会被cache.Controller watch到，并开始执行<code>syncClaim</code>函数：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(ctrl *PersistentVolumeController)</span> <span class="title">syncClaim</span><span class="params">(claim *v1.PersistentVolumeClaim)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">klog.V(<span class="number">4</span>).Infof(<span class="string">&quot;synchronizing PersistentVolumeClaim[%s]: %s&quot;</span>, claimToClaimKey(claim), getClaimStatusForLogging(claim))</span><br><span class="line"></span><br><span class="line"><span class="comment">// Set correct &quot;migrated-to&quot; annotations on PVC and update in API server if</span></span><br><span class="line"><span class="comment">// necessary</span></span><br><span class="line">newClaim, err := ctrl.updateClaimMigrationAnnotations(claim)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="comment">// Nothing was saved; we will fall back into the same</span></span><br><span class="line"><span class="comment">// condition in the next call to this method</span></span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br><span class="line">claim = newClaim</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> !metav1.HasAnnotation(claim.ObjectMeta, pvutil.AnnBindCompleted) &#123;</span><br><span class="line"><span class="keyword">return</span> ctrl.syncUnboundClaim(claim)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">return</span> ctrl.syncBoundClaim(claim)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过<code>pv.kubernetes.io/bind-completed</code> annotation来判断pvc是否已经完成bound操作，如果该PVC未进行bound操作，则调用<code>syncUnboundClaim</code>进行bound操作。</p><p>在进行<code>syncUnboundClaim</code>前，首先会确认PVC是否定义了<strong>延迟绑定</strong>策略：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// IsDelayBindingMode checks if claim is in delay binding mode.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">IsDelayBindingMode</span><span class="params">(claim *v1.PersistentVolumeClaim, classLister storagelisters.StorageClassLister)</span> <span class="params">(<span class="keyword">bool</span>, error)</span></span> &#123;</span><br><span class="line">className := storagehelpers.GetPersistentVolumeClaimClass(claim)</span><br><span class="line"><span class="keyword">if</span> className == <span class="string">&quot;&quot;</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span>, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">class, err := classLister.Get(className)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">if</span> apierrors.IsNotFound(err) &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span>, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span>, err</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> class.VolumeBindingMode == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span>, fmt.Errorf(<span class="string">&quot;VolumeBindingMode not set for StorageClass %q&quot;</span>, className)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> *class.VolumeBindingMode == storage.VolumeBindingWaitForFirstConsumer, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>延迟绑定主要用在Local PersistentVolume的情况下，当采用本地卷作为持久化卷时，如果PVC和PV即时绑定，则可能在pod启动的节点上找不到PV，mount过程会失败，而延迟绑定则将PVC和PV的绑定延后到Pod 调度器中，从而使Volume卷可以被正常挂载到Pod上。</p><p>之后执行PV查找过程，首先从<code>pvIndex</code>中按照<code>AccessModes</code>找到所有符合的PV：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">allPossibleModes := pvIndex.allPossibleMatchingAccessModes(claim.Spec.AccessModes)</span><br></pre></td></tr></table></figure><p>例如PVC请求的PV的AccessMode是<code>ReadWriteOnce</code>，则包含<code>ReadWriteOnce</code>的PV都会被检索出。</p><p>之后通过调用<code>FindMatchingVolume</code>方法找到最合适的PV。</p><p>这里的逻辑是通过遍历符合AccessMode的所有PV，首先判定PV是否已经被其他PVC预绑定（pre-bound）或已经被绑定：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="keyword">if</span> volume.Spec.ClaimRef != <span class="literal">nil</span> &amp;&amp; !IsVolumeBoundToClaim(volume, claim) &#123;</span><br><span class="line">    <span class="keyword">continue</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">IsVolumeBoundToClaim</span><span class="params">(volume *v1.PersistentVolume, claim *v1.PersistentVolumeClaim)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> volume.Spec.ClaimRef == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> claim.Name != volume.Spec.ClaimRef.Name || claim.Namespace != volume.Spec.ClaimRef.Namespace &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> volume.Spec.ClaimRef.UID != <span class="string">&quot;&quot;</span> &amp;&amp; claim.UID != volume.Spec.ClaimRef.UID &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当开启了 延迟绑定后，PV将会被直接跳过，交给Pod调度器进行调度：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> node == <span class="literal">nil</span> &amp;&amp; delayBinding &#123;</span><br><span class="line">    <span class="comment">// PV controller does not bind this claim.</span></span><br><span class="line">    <span class="comment">// Scheduler will handle binding unbound volumes</span></span><br><span class="line">    <span class="comment">// Scheduler path will have node != nil</span></span><br><span class="line">    <span class="keyword">continue</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后会检查PV的状态是否处于 Available 、PVC中定义的labelSelector是否符合要求以及StorageClass是否符合（默认都为空，则为符合），不符合则跳过：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> volume.Status.Phase != v1.VolumeAvailable &#123;</span><br><span class="line">    <span class="comment">// We ignore volumes in non-available phase, because volumes that</span></span><br><span class="line">    <span class="comment">// satisfies matching criteria will be updated to available, binding</span></span><br><span class="line">    <span class="comment">// them now has high chance of encountering unnecessary failures</span></span><br><span class="line">    <span class="comment">// due to API conflicts.</span></span><br><span class="line">    <span class="keyword">continue</span></span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> selector != <span class="literal">nil</span> &amp;&amp; !selector.Matches(labels.Set(volume.Labels)) &#123;</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> storagehelpers.GetPersistentVolumeClass(volume) != requestedClass &#123;</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上都完毕后，从所有的符合条件的PV中找到符合PVC requestSize且最小的一个PV：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> smallestVolume == <span class="literal">nil</span> || smallestVolumeQty.Cmp(volumeQty) &gt; <span class="number">0</span> &#123;</span><br><span class="line">    smallestVolume = volume</span><br><span class="line">    smallestVolumeQty = volumeQty</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> smallestVolume != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="comment">// Found a matching volume</span></span><br><span class="line">    <span class="keyword">return</span> smallestVolume, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上是PV和PVC的调度绑定流程。</p><h4 id="Dynamic-Provisioning"><a href="#Dynamic-Provisioning" class="headerlink" title="Dynamic Provisioning"></a>Dynamic Provisioning</h4><p>这个过程在PersistentVolumeController中完成，而当Pod在实际使用Volume前，需要通过Attach以及Mount流程后，才能真正进行使用。</p><p>而实际的应用场景则是，在环境中可能没有提前创建好可供“bound”的PV，这时候<strong>Dynamic Provisioning</strong>就派上用场了。</p><p>使用Dynamic Provisioning方式很简单，通过定义StorageClass就可以完成。</p><p>以Rook-Ceph的RBD服务为例，可以创建如下格式的StorageClass，以提供块存储服务：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">block-service</span></span><br><span class="line">  <span class="attr">provisioner:</span> <span class="string">ceph.rook.io/block</span></span><br><span class="line">  <span class="attr">parameters:</span></span><br><span class="line">    <span class="attr">pool:</span> <span class="string">replicapool</span></span><br><span class="line">    <span class="attr">clusterNamespace:</span> <span class="string">rook-ceph</span></span><br></pre></td></tr></table></figure><p>通过在PVC中声明storageClassName字段，就可以进行动态使用了：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">claim1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">block-service</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">30Gi</span></span><br></pre></td></tr></table></figure><p>在PVController watch到动态PVC被声明后，首先会寻找该PVC对应的plugin和storageClass:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plugin, storageClass, err := ctrl.findProvisionablePlugin(claim)</span><br></pre></td></tr></table></figure><p>这个过程会通过PersistentVolumeController的findProvisionablePlugin方法来进行寻找in-tree plugin，而find过程的关键在于通过PVC声明的storageClassName寻找对应的in-tree Plugin：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Find a plugin for the class</span></span><br><span class="line"><span class="keyword">if</span> ctrl.csiMigratedPluginManager.IsMigrationEnabledForPlugin(class.Provisioner) &#123;</span><br><span class="line">    <span class="comment">// CSI migration scenario - do not depend on in-tree plugin</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span>, class, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line">plugin, err := ctrl.volumePluginMgr.FindProvisionablePluginByName(class.Provisioner)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> !strings.HasPrefix(class.Provisioner, <span class="string">&quot;kubernetes.io/&quot;</span>) &#123;</span><br><span class="line">        <span class="comment">// External provisioner is requested, do not report error</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span>, class, <span class="literal">nil</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span>, class, err</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> plugin, class, <span class="literal">nil</span></span><br></pre></td></tr></table></figure><p>在1.14之后，PVController会先判断是否属于in-tree plugin到CSI的迁移(migration)场景，如果属于，则会将in-tree的plugin迁移到CSI，关于migration的产生背景，可以看下这篇介绍：<a href="https://kubernetes.io/blog/2019/12/09/kubernetes-1-17-feature-csi-migration-beta/">https://kubernetes.io/blog/2019/12/09/kubernetes-1-17-feature-csi-migration-beta/</a></p><p>简单来说，为了支持Plugin机制的广泛使用，K8S社区越来越倾向于减少in-tree的代码，而通过Plugin的机制来进行扩展，原先in-tree的Plugin也被通过migration的机制，逐渐往CSI上迁，从中也能看出K8S社区对扩展性的考量，未来K8S极有可能成为Plugin的“媒介”系统（目前还未采用Plugin机制的，仅有kube-scheduler，而随着K8S社区的不断演进，kube-scheduler的默认调度器也会和CSI、CNI一样，支持自定义调度插件）。</p><p>继续往下分析，PVController会通过scheduleOperation来传入PV的Operation方法作为闭包，scheduleOperation的作用主要是通过grm（goroutinemap）的读写锁来判定，是否有Operation已经在运行中，运行中的作业会被预先加入goroutinemap中，用以判断。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// goroutinemap</span></span><br><span class="line"><span class="keyword">type</span> goRoutineMap <span class="keyword">struct</span> &#123;</span><br><span class="line">operations                <span class="keyword">map</span>[<span class="keyword">string</span>]operation</span><br><span class="line">exponentialBackOffOnError <span class="keyword">bool</span></span><br><span class="line">cond                      *sync.Cond</span><br><span class="line">lock                      sync.RWMutex</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Attach-amp-Mount"><a href="#Attach-amp-Mount" class="headerlink" title="Attach &amp; Mount"></a>Attach &amp; Mount</h4><p>在实际挂载时，通过ADController调用CSI的Attach操作，并在kubelet中调用Mount操作，完成存储卷和Pod的挂载过程。</p><p>在ADController中，首先会构建出PV对应的VolumeSpec，</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// NewSpecFromPersistentVolume creates an Spec from an v1.PersistentVolume</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewSpecFromPersistentVolume</span><span class="params">(pv *v1.PersistentVolume, readOnly <span class="keyword">bool</span>)</span> *<span class="title">Spec</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> &amp;Spec&#123;</span><br><span class="line">PersistentVolume: pv,</span><br><span class="line">ReadOnly:         readOnly,</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>之后根据VolumeSpec寻找到plugin， 通过调用operation_executor，完成Attach操作。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(oe *operationExecutor)</span> <span class="title">AttachVolume</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">volumeToAttach VolumeToAttach,</span></span></span><br><span class="line"><span class="function"><span class="params">actualStateOfWorld ActualStateOfWorldAttacherUpdater)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">generatedOperations :=</span><br><span class="line">oe.operationGenerator.GenerateAttachVolumeFunc(volumeToAttach, actualStateOfWorld)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> util.IsMultiAttachAllowed(volumeToAttach.VolumeSpec) &#123;</span><br><span class="line"><span class="keyword">return</span> oe.pendingOperations.Run(</span><br><span class="line">volumeToAttach.VolumeName, <span class="string">&quot;&quot;</span> <span class="comment">/* podName */</span>, volumeToAttach.NodeName, generatedOperations)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> oe.pendingOperations.Run(</span><br><span class="line">volumeToAttach.VolumeName, <span class="string">&quot;&quot;</span> <span class="comment">/* podName */</span>, <span class="string">&quot;&quot;</span> <span class="comment">/* nodeName */</span>, generatedOperations)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>而Mount操作则在kubelet中进行，在kubelet中会生成VolumeManager对象。</p><p>关于VolumeManager的处理逻辑会在kubelet的详细介绍文章中介绍。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在了解k8s的CSI plugin编写前，我们需要先了解下有关K8S的持久化存储机制。&lt;/p&gt;</summary>
    
    
    
    
    <category term="k8s" scheme="http://example.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>Cloud Devops</title>
    <link href="http://example.com/2021/04/09/Cloud-Devops/"/>
    <id>http://example.com/2021/04/09/Cloud-Devops/</id>
    <published>2021-04-09T06:55:57.000Z</published>
    <updated>2021-07-13T02:51:49.380Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>容器文件系统</title>
    <link href="http://example.com/2021/04/09/%E5%AE%B9%E5%99%A8%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"/>
    <id>http://example.com/2021/04/09/%E5%AE%B9%E5%99%A8%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/</id>
    <published>2021-04-09T05:44:33.000Z</published>
    <updated>2021-07-13T02:51:49.380Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>linux container</title>
    <link href="http://example.com/2021/04/09/linux-container/"/>
    <id>http://example.com/2021/04/09/linux-container/</id>
    <published>2021-04-09T05:44:06.000Z</published>
    <updated>2021-07-13T02:51:49.380Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>cgroup</title>
    <link href="http://example.com/2021/04/09/cgroup/"/>
    <id>http://example.com/2021/04/09/cgroup/</id>
    <published>2021-04-09T05:43:53.000Z</published>
    <updated>2021-07-13T02:51:49.380Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>容器网络</title>
    <link href="http://example.com/2021/04/09/%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/"/>
    <id>http://example.com/2021/04/09/%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C/</id>
    <published>2021-04-09T05:43:47.000Z</published>
    <updated>2021-07-13T02:51:49.380Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要从docker网络到k8s CNI进行尽可能详细的阐述和分析，笔者能力有限，如有疏漏，那就忽略好了 -_-||。</p><span id="more"></span><h3 id="Docker容器网络"><a href="#Docker容器网络" class="headerlink" title="Docker容器网络"></a>Docker容器网络</h3>]]></content>
    
    
    <summary type="html">&lt;p&gt;本文主要从docker网络到k8s CNI进行尽可能详细的阐述和分析，笔者能力有限，如有疏漏，那就忽略好了 -_-||。&lt;/p&gt;</summary>
    
    
    
    
    <category term="container" scheme="http://example.com/tags/container/"/>
    
  </entry>
  
  <entry>
    <title>K8S Operator</title>
    <link href="http://example.com/2021/04/09/K8S-Operator/"/>
    <id>http://example.com/2021/04/09/K8S-Operator/</id>
    <published>2021-04-09T05:24:48.000Z</published>
    <updated>2021-07-13T02:51:49.380Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>容器问题总结</title>
    <link href="http://example.com/2021/04/09/%E5%AE%B9%E5%99%A8%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/"/>
    <id>http://example.com/2021/04/09/%E5%AE%B9%E5%99%A8%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/</id>
    <published>2021-04-09T05:22:47.000Z</published>
    <updated>2021-07-13T02:51:49.380Z</updated>
    
    <content type="html"><![CDATA[<p><strong>网络部分</strong></p><p>1.Docker中的网络是如何连通的？container和container直接网络访问的流程？</p><span id="more"></span><p>2.如何实现Pod跨宿主机通信？</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;网络部分&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1.Docker中的网络是如何连通的？container和container直接网络访问的流程？&lt;/p&gt;</summary>
    
    
    
    
    <category term="k8s" scheme="http://example.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>文件IO调用</title>
    <link href="http://example.com/2021/04/09/%E6%96%87%E4%BB%B6IO%E8%B0%83%E7%94%A8/"/>
    <id>http://example.com/2021/04/09/%E6%96%87%E4%BB%B6IO%E8%B0%83%E7%94%A8/</id>
    <published>2021-04-09T05:22:18.000Z</published>
    <updated>2021-07-13T02:51:49.380Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>Linux启动过程刨析</title>
    <link href="http://example.com/2021/04/08/linux%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"/>
    <id>http://example.com/2021/04/08/linux%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/</id>
    <published>2021-04-08T13:38:04.000Z</published>
    <updated>2021-07-13T02:51:49.380Z</updated>
    
    <content type="html"><![CDATA[<p>Linux启动过程主要包含boot和startup两个阶段。</p><span id="more"></span><p>*本文不包含硬件相关的加载细节</p><h3 id="引导-Boot-阶段"><a href="#引导-Boot-阶段" class="headerlink" title="引导(Boot)阶段"></a>引导(Boot)阶段</h3><p>Boot阶段始于按下开机键或通过内核指令执行reboot操作，之后会经历以下过程：</p><h4 id="1-BIOS-POST"><a href="#1-BIOS-POST" class="headerlink" title="1.BIOS POST"></a>1.BIOS POST</h4><p>第一阶段启动和Linux本身关系不大，主要围绕硬件启动部分，在绝大大数操作系统上行为是一致的。当计算机被启动时，首先运行的是POST（Power On Self Test 开机自检）过程，这是BIOS（Basic I/O System）的一部分。</p><p>当IBM在1981年设计了第一台PC开始，BIOS就被设计为初始化硬件的组件。POST是BIOS检查计算机硬件，并确保计算机硬件功能正常的阶段。如果POST失败了，计算机将无法正常启动，Boot程序也不会继续。</p><p>BIOS POST过程中会检查硬件的基本引导能力，当定位到可引导设备上的引导扇区时，会发出BIOS中断指令INT 13H中断BIOS POST过程。第一个被找到的引导扇区上包含了一个可用的的引导设备。第一个被找到的引导扇区将会包含一个可用的引导记录并被加载到内存，随后将引导的控制权转移从引导扇区加载的代码中。</p><p>加载引导扇区实际上是引导加载程序的第一阶段。大多数Linux发行版使用了三种引导加载程序：GRUB、GRUB2和LILO，目前用的最多的是GRUB2。</p><h4 id="2-GRUB2"><a href="#2-GRUB2" class="headerlink" title="2.GRUB2"></a>2.GRUB2</h4><p>GRUB2的全称是“GRand Unified Bootloader, version 2”，目前是Linux发行版中最主流的引导加载程序（bootloader）。GRUB2的作用是让计算机能够灵活得找到操作系统Kernel并且加载到内存中。（下文中将用GRUB指代GRUB2）。</p><p>GRUB被设计为多引导规范（<a href="https://en.wikipedia.org/wiki/Multiboot_specification">Multiboot specification</a>）支持，这使得GRUB可以引导Linux的多数版本以及其他开放操作系统，也可以链接到其他专有操作系统的引导记录（例如通过GRUB加载Windows的引导程序）。</p><p>GRUB允许用户选择从任意给定的Linux发行版的不通内核中引导，如果因为内核版本变化导致引导失败，GRUB还支持了故障回滚机制，能够引导到之前的内核版本。GRUB可以使用 <code>/boot/grub/grub.conf</code> 进行回滚策略的变更。</p><p>以下将介绍GRUB2的三个引导阶段：</p><h5 id="Stage-1"><a href="#Stage-1" class="headerlink" title="Stage 1"></a>Stage 1</h5><p>在BIOS POST的POST阶段的末尾，BIOS会搜索连接的磁盘上的引导记录，通常位于主引导记录（<a href="https://en.wikipedia.org/wiki/Master_boot_record">MBR</a>）中，POST会找到第一个引导记录并加载到内存中，然后开始执行引导记录。GRUB2 stage 1即执行引导程序代码，这块被设计得非常小，因为它必须与分区表一起放在硬盘驱动器的第一个512字节扇区中。在经典的通用MBR中，为实际引导代码分区的空间量是446字节。Stage 1中的446字节文件名为<code>boot.img</code>，头部的446中不包含单独的引导分区。</p><p>由于引导记录大小的限制，使得其无法直接获取文件系统结构，因此，Stage 1阶段的唯一目的是定义并加载Stage 1.5，GRUB Stage 1.5阶段必须位于引导记录本身和驱动器第一个分区之间，GRUB Stage 1.5被加载到Ram后，控制权随即转为Stage 1.5</p><h5 id="Stage-1-5"><a href="#Stage-1-5" class="headerlink" title="Stage 1.5"></a>Stage 1.5</h5><p>Stage 1.5的工作主要是加载寻找 /boot目录中Stage 2阶段所必须的驱动。</p><p>GRUB Stage 1.5必须位于引导记录本身与磁盘驱动器第一个分区之间的空间中。硬盘驱动器的第一个分区从扇区63开始，而MBR在扇区0剩下的62个扇区（512字节-31744字节）中存放了执行Stage 1.5的<code>core.img</code>，<code>core.img</code>大小被设计为25389字节，可以被存放在MBR和磁盘第一个分区之间。</p><p>对于Stage 1.5来说，它能够存放比Stage 1多的多的代码，一般来说，一些常见文件系统的驱动程序会存放在此（例如EXT、FAT、NTFS等）。GRUB2的core.img比GRUB1更复杂，功能更强大，GRUB2的core.img可以直接位于标准EXT文件系统上（不支持放在逻辑卷上），所以Stage 2的标准路径是<code>/boot</code> 目录，一般是<code>/boot/grub2</code>。</p><p>需要注意的是，<code>/boot</code>目录必须创建在GRUB支持的文件系统上。</p><h5 id="Stage-2"><a href="#Stage-2" class="headerlink" title="Stage 2"></a>Stage 2</h5><p>与GRUB1一样，GRUB2也支持从多种Linux内核之一进行引导。红帽软件包管理器DNF支持保留内核的多个版本，因此，如果最新版本的内核出现问题，则可以引导较旧版本的内核。默认情况下，GRUB提供已安装内核的预引导菜单，包括救援选项和恢复选项（如果已配置）。</p><p>GRUB Stage2阶段所需文件都在 <code>/boot/grub2</code>目录中，GRUB Stage2阶段中没有Stage1和1.5那样的image文件，主要会由运行时Kernel Modules构成，一般从<code>/boot/grub2/i386-pc</code>目录中加载。</p><p>GRUB Stage2的职责主要是定位Linux Kernel并加载到RAM中，并将整个控制权移交给kernel。</p><p>Kernel及其相关文件都位于/boot目录中，Kernel文件一般以vmlinuz开头命名，通过列出 /boot 目录的内容，可以查看当前系统安装的内核。</p><p>GRUB2 和 1都支持多内核引导。RedHat的包管理系统DNF支持在仓库中保留多个Kernel版本，如果最新版本内核出现问题，可以通过GRUB提供的内核预引导菜单（pre-boot menu），引导前一个版本的内核。</p><h5 id="Kernel"><a href="#Kernel" class="headerlink" title="Kernel"></a>Kernel</h5><p>为了节省磁盘空间，所有的内核均采用自解压的压缩格式。内核、初始RAM磁盘映像（InitRamFs）以及硬盘的社区映射都位于 /boot目录中。</p><p>选定的内核被加载到内存开始执行时，首先进行自解压，提取可执行作业，并加载。内核提取后首先systemd，并将启动控制权进行交接。</p><p>Boot阶段到此全部结束，此时，Linux Kernel和systemd程序正在运行。</p><h3 id="启动-Startup-阶段"><a href="#启动-Startup-阶段" class="headerlink" title="启动(Startup)阶段"></a>启动(Startup)阶段</h3><p>Startup阶段和Boot阶段完成后随即开始，主要工作是让计算机能够真正执行生产作业。</p><h5 id="0号进程和1号进程"><a href="#0号进程和1号进程" class="headerlink" title="0号进程和1号进程"></a>0号进程和1号进程</h5><p>systemd是系统的1号进程，在1号进程启动前，系统会自动创建0号进程，0号进程的pid=0，也是唯一一个没有通过<code>fork</code>或者<code>kernel_thread</code>生成的进程。</p><p>0号进程是系统所有进程的先祖，进程描述符<code>init_task</code>是内核静态创建的，而它在初始化的时候通过<code>kernel_thread</code>的方式创建了两个内核线程，分别是<code>kernel_init</code>和<code>kthreadd</code>，其中<code>kernel_init</code>为1号进程。</p><p>0号进程创建1号进程的方式如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kernel_thread(kernel_init, <span class="literal">NULL</span>, CLONE_FS);</span><br></pre></td></tr></table></figure><p>我们发现1号进程的执行函数就是kernel_init，kernel_init函数将完成设备驱动程序的初始化，并调用init_post函数启动用户空间的init进程即systemd。</p><h5 id="systemd"><a href="#systemd" class="headerlink" title="systemd"></a>systemd</h5><p>systemd是所有用户进程的祖先，它负责使Linux主机达到可以完成生产性工作的状态。它的某些功能比旧的init程序要更为广泛。</p><p>首先，systemd会挂载<code>/etc/fstab</code>定义的文件系统，包括所有交换分区和普通分区。此时，它可以访问/etc目录来确定系统配置相关信息。当找到配置文件<code>/etc/systemd/system/default.target</code>时，会使用该配置文件来确定将主机引导到的状态或目标。 <code>default.target</code>文件是指向真实目标文件的链接。对于带GUI界面的系统，通常将其作为<code>graphic.target</code>，等效于旧SystemV init中的runlevel 5。对于不带GUI解密的系统，默认值则为<code>multi-user.target</code>，类似于SystemV中的runlevel 3，<code>emergency.target</code>则与单用户模式相似。</p><p>下表是对systemd targets与的systemV runlevel的比较。 systemd target aliases 由systemd提供，用于向后兼容。target aliases 允许脚本使用init 3这样的SystemV命令来更改运行级别。SystemV命令将转发给systemd进行解释和执行。</p><table><thead><tr><th><strong>SystemV Runlevel</strong></th><th><strong>systemd target</strong></th><th><strong>systemd target aliases</strong></th><th><strong>Description</strong></th></tr></thead><tbody><tr><td></td><td>halt.target</td><td></td><td>Halts the system without powering it down.</td></tr><tr><td>0</td><td>poweroff.target</td><td>runlevel0.target</td><td>Halts the system and turns the power off.</td></tr><tr><td>S</td><td>emergency.target</td><td></td><td>Single user mode. No services are running; filesystems are not mounted. This is the most basic level of operation with only an emergency shell running on the main console for the user to interact with the system.</td></tr><tr><td>1</td><td>rescue.target</td><td>runlevel1.target</td><td>A base system including mounting the filesystems with only the most basic services running and a rescue shell on the main console.</td></tr><tr><td>2</td><td></td><td>runlevel2.target</td><td>Multiuser, without NFS but all other non-GUI services running.</td></tr><tr><td>3</td><td>multi-user.target</td><td>runlevel3.target</td><td>All services running but command line interface (CLI) only.</td></tr><tr><td>4</td><td></td><td>runlevel4.target</td><td>Unused.</td></tr><tr><td>5</td><td>graphical.target</td><td>runlevel5.target</td><td>multi-user with a GUI.</td></tr><tr><td>6</td><td>reboot.target</td><td>runlevel6.target</td><td>Reboot</td></tr><tr><td></td><td>default.target</td><td></td><td>This target is always aliased with a symbolic link to either multi-user.target or graphical.target. systemd always uses the default.target to start the system. The default.target should never be aliased to halt.target, poweroff.target, or reboot.target.</td></tr></tbody></table><p>每个target都有对应的配置文件可供配置，并且具备相互依赖的特性，下图描述了target的依赖关系。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">local-fs-pre.target</span><br><span class="line">            |</span><br><span class="line">            v</span><br><span class="line">   (various mounts and   (various swap   (various cryptsetup</span><br><span class="line">    fsck services...)     devices...)        devices...)       (various low-level   (various low-level</span><br><span class="line">            |                  |                  |             services: udevd,     API VFS mounts:</span><br><span class="line">            v                  v                  v             tmpfiles, random     mqueue, configfs,</span><br><span class="line">     local-fs.target      swap.target     cryptsetup.target    seed, sysctl, ...)      debugfs, ...)</span><br><span class="line">            |                  |                  |                    |                    |</span><br><span class="line">            \__________________|_________________ | ___________________|____________________&#x2F;</span><br><span class="line">                                                 \|&#x2F;</span><br><span class="line">                                                  v</span><br><span class="line">                                           sysinit.target</span><br><span class="line">                                                  |</span><br><span class="line">             ____________________________________&#x2F;|\________________________________________</span><br><span class="line">            &#x2F;                  |                  |                    |                    \</span><br><span class="line">            |                  |                  |                    |                    |</span><br><span class="line">            v                  v                  |                    v                    v</span><br><span class="line">        (various           (various               |                (various          rescue.service</span><br><span class="line">       timers...)          paths...)              |               sockets...)               |</span><br><span class="line">            |                  |                  |                    |                    v</span><br><span class="line">            v                  v                  |                    v              rescue.target</span><br><span class="line">      timers.target      paths.target             |             sockets.target</span><br><span class="line">            |                  |                  |                    |</span><br><span class="line">            v                  \_________________ | ___________________&#x2F;</span><br><span class="line">                                                 \|&#x2F;</span><br><span class="line">                                                  v</span><br><span class="line">                                            basic.target</span><br><span class="line">                                                  |</span><br><span class="line">             ____________________________________&#x2F;|                                 emergency.service</span><br><span class="line">            &#x2F;                  |                  |                                         |</span><br><span class="line">            |                  |                  |                                         v</span><br><span class="line">            v                  v                  v                                 emergency.target</span><br><span class="line">        display-        (various system    (various system</span><br><span class="line">    manager.service         services           services)</span><br><span class="line">            |             required for            |</span><br><span class="line">            |            graphical UIs)           v</span><br><span class="line">            |                  |           multi-user.target</span><br><span class="line">            |                  |                  |</span><br><span class="line">            \_________________ | _________________&#x2F;</span><br><span class="line">                              \|&#x2F;</span><br><span class="line">                               v</span><br><span class="line">                     graphical.target</span><br></pre></td></tr></table></figure><p>根据依赖拓扑完成启动后，Linux系统结束启动过程。</p><h3 id="附录：关于initramd的定制"><a href="#附录：关于initramd的定制" class="headerlink" title="附录：关于initramd的定制"></a>附录：关于initramd的定制</h3><p>解压：</p><p><code>xz -dc &lt; initrd.img| cpio -idmv</code></p><p>打包：</p><p><code>find . 2&gt;/dev/null | cpio -c -o | xz -9 --format=xz --check=crc32 &gt; /tmp/new.img</code></p><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><p><a href="https://opensource.com/article/17/2/linux-boot-and-startup">https://opensource.com/article/17/2/linux-boot-and-startup</a></p><p><a href="https://blog.csdn.net/gatieme/article/details/51532804">https://blog.csdn.net/gatieme/article/details/51532804</a></p><p><a href="https://www.golinuxcloud.com/update-rebuild-initrd-image-centos-rhel-7-8/#Method_2_Extract_initrd_image">https://www.golinuxcloud.com/update-rebuild-initrd-image-centos-rhel-7-8/#Method_2_Extract_initrd_image</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Linux启动过程主要包含boot和startup两个阶段。&lt;/p&gt;</summary>
    
    
    
    
    <category term="system" scheme="http://example.com/tags/system/"/>
    
  </entry>
  
</feed>
